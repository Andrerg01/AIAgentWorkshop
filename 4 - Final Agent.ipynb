{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d13ad2c0-4d25-4995-8c92-707e37746405",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Final Agent\n",
    "Okay, now we're cooking. Our agent can access some data, that's super cool! But it's not the best now, is it? It can access data, but it loads the ENTIRE dataset into the chat! That's not practical. Especially if our dataset as very large.\n",
    "\n",
    "What we'll do next is to QUERY data SMARTLY! We'll have agents write the SQL to query our data for us. And that will be the final form of our agent.\n",
    "\n",
    "---\n",
    "\n",
    "In this module, we'll make up some large mock dataset, and have the agent query from that as necessary with the SQL query that seems appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebb22fce-9432-49cd-8ea0-f74ccffd2114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1 Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8896e393-f1f3-4cc1-a1c9-6f457cf66d6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.1 Installs\n",
    "We'll be installig `duckdb` so we can do sql queries on pandas dataframes, again, educational purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7e71382-850b-49fc-8715-30212b261580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph==0.0.36 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (0.0.36)\nRequirement already satisfied: langchain<0.2.0,>=0.1.20 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (0.1.20)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.20 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (0.1.53)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (2.31.0)\nRequirement already satisfied: duckdb in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (1.3.2)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (2.0.41)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (3.12.14)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.6.7)\nRequirement already satisfied: langchain-community<0.1,>=0.0.38 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.0.38)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.0.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.1.147)\nRequirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (1.23.5)\nRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (1.10.6)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (8.2.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.20) (1.33)\nRequirement already satisfied: packaging<24.0,>=23.2 in /databricks/python3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.20) (23.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests) (2023.7.22)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.20) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (1.0.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.20) (4.10.0)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.20) (3.2.3)\nRequirement already satisfied: anyio in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (0.16.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20) (0.4.3)\nRequirement already satisfied: sniffio>=1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-b1ee44da-f69b-48c2-82c4-fedc154c6466/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (1.3.1)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install \"langgraph==0.0.36\" \"langchain>=0.1.20,<0.2.0\" \"langchain-core>=0.1.20,<0.2.0\" requests duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34b1db82-c78b-4985-a911-cf3cc44c58c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mWarning: statements after `dbutils.library.restartPython()` will execute before Python is restarted.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "dbutils.library.restartPython() # Necessary for clearing cache and whatnots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18fe56eb-8be0-40b3-ab9f-36a65398d879",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.2 Imports\n",
    "Importing `pandas`, `pandassql`, and `numpy` to generate and query the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ef9f677-768b-4478-9c0e-c430aa8c63d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing import Dict, List, Optional, TypedDict\n",
    "import requests, json, textwrap, datetime\n",
    "import json\n",
    "import pandas as pd # <-- New Import\n",
    "import duckdb # <-- New Import\n",
    "import numpy as np # <-- New Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71a4a451-5fd3-478e-adf2-3575d9a2ecf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.3 Config Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "260807c5-2d26-449d-93bf-cca653d7ecbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CHAT_ENDPOINT = \"databricks-llama-4-maverick\" # Chat Model\n",
    "INSTRUCT_ENDPOINT = \"databricks-meta-llama-3-1-8b-instruct\" # Instruct Model\n",
    "DATABRICKS_URL = \"https://dbc-864a442b-39b8.cloud.databricks.com\" # The Base URL at the top\n",
    "DATABRICKS_TOKEN = \"dapi763c08facfcf240733ac46730443c6cf\" # Your own token\n",
    "VERBOSE = True  # global toggle to see hidden outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1babf213-37d5-4901-8ae0-4f122d9d1ce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.4 - Mock Data\n",
    "Some fake sales data we can play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "670a32f0-ede8-46c2-8bb2-4d02b692e7e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_up_mock_data(n = 1000):\n",
    "    clients = [\"Grandma's Cookies\", \"VolksWagen\", \"The President of the United States\", \"Carl\", \"Blockbuster\"]\n",
    "    products = [\"Cookies\", \"Jet Engine\", \"Enriched Uranium\", \"Dirt\", \"Fake Promises\"]\n",
    "    df = pd.DataFrame({\n",
    "        \"client\": np.random.choice(clients, n),\n",
    "        \"product\": np.random.choice(products, n),\n",
    "        \"quantity\": np.random.randint(0, 100, n),\n",
    "        # Float between 0 and 1000\n",
    "        \"price\": np.random.rand(n) * 1000,\n",
    "        \"date\": pd.date_range(start=\"2024-01-01\", end=\"2024-12-31\", periods=n)\n",
    "    })\n",
    "    return df\n",
    "sales_data = make_up_mock_data(1000)\n",
    "\n",
    "schema_catalog = {\n",
    "    \"sales_data\": (\n",
    "        \"The 'sales_data' table has the following columns:\\n\"\n",
    "        \"- client (string): the customer name\\n\"\n",
    "        \"- product (string): the item sold\\n\"\n",
    "        \"- quantity (int): number of units sold\\n\"\n",
    "        \"- price (float): price per unit\\n\"\n",
    "        \"- date (datetime): date of transaction\\n\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "263300b2-ca2b-4de8-84c4-e9ab14276fcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2 Defining Functions and Classes\n",
    "\n",
    "Now here we'll change some things. \n",
    "\n",
    "The AgentState will include a new field called `schema_catalog`, so that any node can look at the data catalog and know its organized.\n",
    "\n",
    "Instead of the router routing the state to a tool, it will route it to another agent (`sales_data_agent`), which will look at the state, and write a proper SQL query to use against the data, and send it to the `sales_data_tool` to apply it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6078bd8-a629-426a-874f-af147ccf9180",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.1 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2143af1-b6d2-4907-b1b8-10ff973e2a1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict, total=False):\n",
    "    \"\"\"Conversation state passed between graph nodes.\"\"\"\n",
    "    messages: List[Dict[str, str]]   # chat history in OpenAI‑style format\n",
    "    verbose: bool                    # toggle debug prints\n",
    "    output: Optional[str]            # assistant response\n",
    "    available_tools: Optional[Dict[str, str]]   # names and descriptions of tools the router can pick\n",
    "    tool_context: Optional[str]                 # extra context (cleared each turn)\n",
    "    schema_catalog: Optional[Dict[str, str]]    # catalog of schemas and their descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48e96563-7f84-4528-bd56-af94419f9069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2 - Connection Function\n",
    "\n",
    "This one remains unchanged, nothing new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c63752c4-ff29-4a86-ad42-c169c5f3f81f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The databricks function we know well. I added some type restrictions so there's no confusion, but that's not\n",
    "def databricks_llm(messages: List[Dict[str, str]], *, model_endpoint: str = CHAT_ENDPOINT, verbose: bool = False) -> str:\n",
    "    \"\"\"Call a Databricks serving endpoint that follows the OpenAI chat format.\"\"\"\n",
    "    if verbose:\n",
    "        print(\"\\n=== LLM CALL →\", model_endpoint)\n",
    "        for m in messages:\n",
    "            print(f\"{m['role'].upper()}: {textwrap.shorten(m['content'], width=120)}\")\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {DATABRICKS_TOKEN}\",\n",
    "        \"Content-Type\":  \"application/json\"\n",
    "    }\n",
    "    body = {\n",
    "        \"messages\":   messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\":  1000\n",
    "    }\n",
    "\n",
    "    resp = requests.post(f\"{DATABRICKS_URL}/serving-endpoints/{model_endpoint}/invocations\", headers=headers, json=body)\n",
    "    resp.raise_for_status()\n",
    "    content = resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"LLM RESPONSE:\", content[:300] + (\"…\" if len(content) > 300 else \"\"))\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465f70ad-123f-4649-99a9-9f2795eba3a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.3 - Defining Agents and Tools as Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44c1c4a7-0477-4f63-9cd4-4179cf57b809",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The chat agent will be the same as before, except we'll append the tool context to the chat prompt\n",
    "def chat_agent(state: AgentState) -> AgentState:\n",
    "    if state.get(\"verbose\"): print(\"\\n--- CHAT AGENT NODE ---\")\n",
    "\n",
    "    msgs = state[\"messages\"]\n",
    "\n",
    "    reply = databricks_llm(\n",
    "        msgs + [{\"role\":\"user\", \"content\":f\"TOOLS CONTEXT:\\n{state['tool_context']}\"}],\n",
    "        model_endpoint=CHAT_ENDPOINT,\n",
    "        verbose=state.get(\"verbose\", False),\n",
    "    )\n",
    "\n",
    "    state[\"messages\"] = state[\"messages\"] + [{\"role\": \"assistant\", \"content\": reply}]\n",
    "    state[\"output\"]   = reply\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdc46a0e-ad2d-4761-b6d5-be092e3bee78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sales_data_agent(state: AgentState) -> AgentState:\n",
    "    if state.get(\"verbose\"): print(\"\\n--- SALES DATA AGENT NODE ---\")\n",
    "\n",
    "    schema = state.get(\"schema_catalog\", {}).get(\"sales_data\", \"\")\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an assistant that writes SQL queries to analyze sales data.\\n\\n\"\n",
    "        f\"{schema}\\n\\n\"\n",
    "        \"Based on the conversation below, write a SQL query that answers the user's request.\\n\"\n",
    "        \"Respond with ONLY the query, wrapped like this:\\n\"\n",
    "        \"```sql\\nSELECT ...\\n```\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + [\n",
    "        m for m in state[\"messages\"] if m[\"role\"] != \"system\"\n",
    "    ]\n",
    "\n",
    "    llm_response = databricks_llm(\n",
    "        messages,\n",
    "        model_endpoint=CHAT_ENDPOINT,\n",
    "        verbose=state.get(\"verbose\", False),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        start = llm_response.find(\"```\")\n",
    "        end = llm_response.rfind(\"```\")\n",
    "        sql = llm_response[start + 3:end].strip()\n",
    "        if sql.lower().startswith(\"sql\"):\n",
    "            sql = sql[3:].strip()\n",
    "    except Exception:\n",
    "        sql = \"(invalid SQL format)\"\n",
    "\n",
    "    if state.get(\"verbose\"): print(\"Generated SQL:\\n\", sql)\n",
    "\n",
    "    state[\"output\"] = sql\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b622b43e-df1b-4eb4-96cf-22eb1fa1ea13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sales_data_tool(state: AgentState) -> AgentState:\n",
    "    if state.get(\"verbose\"):\n",
    "        print(\"\\n--- SALES DATA TOOL NODE ---\")\n",
    "\n",
    "    raw_sql = str(state[\"output\"]).strip(\"`\").strip()\n",
    "    if raw_sql.lower().startswith(\"sql\"):\n",
    "        raw_sql = raw_sql[3:].strip()\n",
    "\n",
    "    # DuckDB happily ignores a trailing semicolon\n",
    "    query = raw_sql.rstrip(\";\")\n",
    "\n",
    "    if state.get(\"verbose\"):\n",
    "        print(\"Executing SQL with DuckDB:\\n\", query)\n",
    "\n",
    "    # run against the in-memory DataFrame\n",
    "    try:\n",
    "        result_df = duckdb.query_df(sales_data, \"sales_data\", query).to_df()\n",
    "        context = result_df.to_string(index=False)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"SQL execution failed: {e}\")  # halt on error\n",
    "\n",
    "    if state.get(\"verbose\"):\n",
    "        print(\"SQL result:\\n\", context)\n",
    "\n",
    "    state[\"tool_context\"] = context\n",
    "    state[\"output\"]       = context\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5ca6bfb-50f4-4eab-8546-c16117f9fe3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def router_agent(state: AgentState) -> AgentState:\n",
    "    if state.get(\"verbose\"): print(\"\\n--- ROUTER NODE ---\")\n",
    "\n",
    "    tool_lines = [\n",
    "        f\"- {name}: {desc}\"\n",
    "        for name, desc in (state.get(\"available_tools\") or {}).items()\n",
    "    ]\n",
    "    tool_catalog = \"\\n\".join(tool_lines) or \"none\"\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an AI router. Choose the single best tool for answering the user's latest message.\\n\\n\"\n",
    "        f\"Available tools:\\n{tool_catalog}\\n\\n\"\n",
    "        \"Return ONLY a JSON object like {\\\"tool\\\": \\\"chat\\\"} or {\\\"tool\\\": \\\"sales_data\\\"}.\"\n",
    "    )\n",
    "\n",
    "    llm_response = databricks_llm(\n",
    "        [{\"role\": \"system\", \"content\": system_prompt}] +\n",
    "        [m for m in state[\"messages\"] if m[\"role\"] != \"system\"],\n",
    "        model_endpoint=INSTRUCT_ENDPOINT,\n",
    "        verbose=state.get(\"verbose\", False),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        start = llm_response.rfind(\"{\")\n",
    "        end = llm_response.rfind(\"}\")\n",
    "        decision_json = llm_response[start:end + 1]\n",
    "        decision = json.loads(decision_json)\n",
    "    except Exception:\n",
    "        decision = {\"tool\": \"chat\"}\n",
    "\n",
    "    if state.get(\"verbose\"): print(f\"Routing decision: {decision}\")\n",
    "    state[\"output\"] = json.dumps(decision)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cae5deba-811e-4b9c-8792-ab1f66a1cb92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3 Initializing Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c71e87a-e2a1-435a-92be-5e5a9bd5df84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.1 - Defining Graph\n",
    "\n",
    "Similar logic as last time, but now we'll connect the `sales_data_agent` to `sales_data_tool`, which will then go to `chat_agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "531e03e1-383f-473a-aef7-489621b613ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "g = StateGraph(AgentState)\n",
    "\n",
    "g.add_node(\"router_agent\", RunnableLambda(router_agent))\n",
    "g.add_node(\"sales_data_agent\", RunnableLambda(sales_data_agent))\n",
    "g.add_node(\"sales_data_tool\", RunnableLambda(sales_data_tool))\n",
    "g.add_node(\"chat_agent\", RunnableLambda(chat_agent))\n",
    "\n",
    "g.set_entry_point(\"router_agent\")\n",
    "\n",
    "def pick_next(state: AgentState) -> str:\n",
    "    return json.loads(state[\"output\"])[\"tool\"]\n",
    "\n",
    "g.add_conditional_edges(\n",
    "    \"router_agent\",\n",
    "    pick_next,\n",
    "    {\n",
    "        \"chat\": \"chat_agent\",\n",
    "        \"sales_data\": \"sales_data_agent\"\n",
    "    },\n",
    ")\n",
    "\n",
    "g.add_edge(\"sales_data_agent\", \"sales_data_tool\")\n",
    "g.add_edge(\"sales_data_tool\", \"chat_agent\")\n",
    "g.add_edge(\"chat_agent\", END)\n",
    "\n",
    "assistant_graph = g.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ae6c8d5-bde1-4b46-bf68-9c23934d25ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2 - Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6230e997-143e-4aa7-ad01-132ea2aa80ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  How many sales to Blockbuster do I have?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- ROUTER NODE ---\n\n=== LLM CALL → databricks-meta-llama-3-1-8b-instruct\nSYSTEM: You are an AI router. Choose the single best tool for answering the user's latest message. Available tools: - [...]\nUSER: How many sales to Blockbuster do I have?\nLLM RESPONSE: {\"tool\": \"sales_data\"}\nRouting decision: {'tool': 'sales_data'}\n\n--- SALES DATA AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick\nSYSTEM: You are an assistant that writes SQL queries to analyze sales data. The 'sales_data' table has the following [...]\nUSER: How many sales to Blockbuster do I have?\nLLM RESPONSE: ```sql\nSELECT COUNT(*) \nFROM sales_data \nWHERE client = 'Blockbuster';\n```\nGenerated SQL:\n SELECT COUNT(*) \nFROM sales_data \nWHERE client = 'Blockbuster';\n\n--- SALES DATA TOOL NODE ---\nExecuting SQL with DuckDB:\n SELECT COUNT(*) \nFROM sales_data \nWHERE client = 'Blockbuster'\n\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick\nSYSTEM: You are a helpful AI Agent. You have access to sales data if needed.\nUSER: How many sales to Blockbuster do I have?\nUSER: TOOLS CONTEXT: count_star() 211\nLLM RESPONSE: You have 211 sales to Blockbuster.\n\n---\n\nAssistant: You have 211 sales to Blockbuster.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  Awesome, can you give me the total profit for those sales?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- ROUTER NODE ---\n\n=== LLM CALL → databricks-meta-llama-3-1-8b-instruct\nSYSTEM: You are an AI router. Choose the single best tool for answering the user's latest message. Available tools: - [...]\nUSER: How many sales to Blockbuster do I have?\nASSISTANT: You have 211 sales to Blockbuster.\nUSER: Awesome, can you give me the total profit for those sales?\nLLM RESPONSE: {\"tool\": \"sales_data\"}\nRouting decision: {'tool': 'sales_data'}\n\n--- SALES DATA AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick\nSYSTEM: You are an assistant that writes SQL queries to analyze sales data. The 'sales_data' table has the following [...]\nUSER: How many sales to Blockbuster do I have?\nASSISTANT: You have 211 sales to Blockbuster.\nUSER: Awesome, can you give me the total profit for those sales?\nLLM RESPONSE: To get the total profit from sales to Blockbuster, we first need to identify the total number of sales to Blockbuster and then calculate the total revenue. \n\nLet's directly write the SQL query for it.\n\n```sql\nSELECT SUM(quantity * price) \nFROM sales_data \nWHERE client = 'Blockbuster';\n```\nGenerated SQL:\n SELECT SUM(quantity * price) \nFROM sales_data \nWHERE client = 'Blockbuster';\n\n--- SALES DATA TOOL NODE ---\nExecuting SQL with DuckDB:\n SELECT SUM(quantity * price) \nFROM sales_data \nWHERE client = 'Blockbuster'\n\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick\nSYSTEM: You are a helpful AI Agent. You have access to sales data if needed.\nUSER: How many sales to Blockbuster do I have?\nASSISTANT: You have 211 sales to Blockbuster.\nUSER: Awesome, can you give me the total profit for those sales?\nUSER: TOOLS CONTEXT: sum((quantity * price)) 4.596505e+06\nLLM RESPONSE: The total profit for your 211 sales to Blockbuster is approximately $4,596,505.\n\n---\n\nAssistant: The total profit for your 211 sales to Blockbuster is approximately $4,596,505.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  What are all the clients I have?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- ROUTER NODE ---\n\n=== LLM CALL → databricks-meta-llama-3-1-8b-instruct\nSYSTEM: You are an AI router. Choose the single best tool for answering the user's latest message. Available tools: - [...]\nUSER: How many sales to Blockbuster do I have?\nASSISTANT: You have 211 sales to Blockbuster.\nUSER: Awesome, can you give me the total profit for those sales?\nASSISTANT: The total profit for your 211 sales to Blockbuster is approximately $4,596,505.\nUSER: What are all the clients I have?\nLLM RESPONSE: {\"tool\": \"sales_data\"}\nRouting decision: {'tool': 'sales_data'}\n\n--- SALES DATA AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick\nSYSTEM: You are an assistant that writes SQL queries to analyze sales data. The 'sales_data' table has the following [...]\nUSER: How many sales to Blockbuster do I have?\nASSISTANT: You have 211 sales to Blockbuster.\nUSER: Awesome, can you give me the total profit for those sales?\nASSISTANT: The total profit for your 211 sales to Blockbuster is approximately $4,596,505.\nUSER: What are all the clients I have?\nLLM RESPONSE: ```sql\nSELECT DISTINCT client FROM sales_data;\n```\nGenerated SQL:\n SELECT DISTINCT client FROM sales_data;\n\n--- SALES DATA TOOL NODE ---\nExecuting SQL with DuckDB:\n SELECT DISTINCT client FROM sales_data\n\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick\nSYSTEM: You are a helpful AI Agent. You have access to sales data if needed.\nUSER: How many sales to Blockbuster do I have?\nASSISTANT: You have 211 sales to Blockbuster.\nUSER: Awesome, can you give me the total profit for those sales?\nASSISTANT: The total profit for your 211 sales to Blockbuster is approximately $4,596,505.\nUSER: What are all the clients I have?\nUSER: TOOLS CONTEXT: client Carl Grandma's Cookies The President of the United States VolksWagen Blockbuster\nLLM RESPONSE: You have the following clients: \n1. Carl\n2. Grandma's Cookies\n3. The President of the United States\n4. VolksWagen\n5. Blockbuster\n\nLet me know if you need any further assistance!\n\n---\n\nAssistant: You have the following clients: \n1. Carl\n2. Grandma's Cookies\n3. The President of the United States\n4. VolksWagen\n5. Blockbuster\n\nLet me know if you need any further assistance!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  What's the most popular item sold to the president?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- ROUTER NODE ---\n\n=== LLM CALL → databricks-meta-llama-3-1-8b-instruct\nSYSTEM: You are an AI router. Choose the single best tool for answering the user's latest message. Available tools: - [...]\nUSER: How many sales to Blockbuster do I have?\nASSISTANT: You have 211 sales to Blockbuster.\nUSER: Awesome, can you give me the total profit for those sales?\nASSISTANT: The total profit for your 211 sales to Blockbuster is approximately $4,596,505.\nUSER: What are all the clients I have?\nASSISTANT: You have the following clients: 1. Carl 2. Grandma's Cookies 3. The President of the United States 4. VolksWagen [...]\nUSER: What's the most popular item sold to the president?\nLLM RESPONSE: {\"tool\": \"sales_data\"}\nRouting decision: {'tool': 'sales_data'}\n\n--- SALES DATA AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick\nSYSTEM: You are an assistant that writes SQL queries to analyze sales data. The 'sales_data' table has the following [...]\nUSER: How many sales to Blockbuster do I have?\nASSISTANT: You have 211 sales to Blockbuster.\nUSER: Awesome, can you give me the total profit for those sales?\nASSISTANT: The total profit for your 211 sales to Blockbuster is approximately $4,596,505.\nUSER: What are all the clients I have?\nASSISTANT: You have the following clients: 1. Carl 2. Grandma's Cookies 3. The President of the United States 4. VolksWagen [...]\nUSER: What's the most popular item sold to the president?\nLLM RESPONSE: <|python_start|>```sql\nSELECT product, SUM(quantity) as total_quantity\nFROM sales_data\nWHERE client = 'The President of the United States'\nGROUP BY product\nORDER BY total_quantity DESC\nLIMIT 1;\n```<|python_end|>\nGenerated SQL:\n SELECT product, SUM(quantity) as total_quantity\nFROM sales_data\nWHERE client = 'The President of the United States'\nGROUP BY product\nORDER BY total_quantity DESC\nLIMIT 1;\n\n--- SALES DATA TOOL NODE ---\nExecuting SQL with DuckDB:\n SELECT product, SUM(quantity) as total_quantity\nFROM sales_data\nWHERE client = 'The President of the United States'\nGROUP BY product\nORDER BY total_quantity DESC\nLIMIT 1\n\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick\nSYSTEM: You are a helpful AI Agent. You have access to sales data if needed.\nUSER: How many sales to Blockbuster do I have?\nASSISTANT: You have 211 sales to Blockbuster.\nUSER: Awesome, can you give me the total profit for those sales?\nASSISTANT: The total profit for your 211 sales to Blockbuster is approximately $4,596,505.\nUSER: What are all the clients I have?\nASSISTANT: You have the following clients: 1. Carl 2. Grandma's Cookies 3. The President of the United States 4. VolksWagen [...]\nUSER: What's the most popular item sold to the president?\nUSER: TOOLS CONTEXT: product total_quantity Fake Promises 2627.0\nLLM RESPONSE: The most popular item sold to the President of the United States is \"Fake Promises\" with a total quantity of 2627.0 units.\n\n---\n\nAssistant: The most popular item sold to the President of the United States is \"Fake Promises\" with a total quantity of 2627.0 units.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:132)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:132)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:466)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:757)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:83)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:83)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:83)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:83)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:735)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:926)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$4(Chauffeur.scala:952)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:951)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:1006)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:777)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1037)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:957)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:552)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:522)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:806)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:806)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:769)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:751)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:283)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:283)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:415)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:132)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:132)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:466)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:757)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:83)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:83)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:83)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:83)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:735)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:926)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$4(Chauffeur.scala:952)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:951)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:1006)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:777)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1037)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:957)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:552)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:522)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:806)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:806)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:769)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:751)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:283)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:283)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:415)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    {'role': 'system', 'content': 'You are a helpful AI Agent. You have access to sales data if needed.'}\n",
    "]\n",
    "while True:\n",
    "    user_text = input(\"You: \").strip()\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_text})\n",
    "\n",
    "    state: AgentState = {\n",
    "        \"messages\": chat_history,\n",
    "        \"verbose\": VERBOSE,\n",
    "        \"available_tools\": {\n",
    "            \"chat\": \"Continue the conversation naturally\",\n",
    "            \"sales_data\": \"Query the internal sales database using SQL\"\n",
    "        },\n",
    "        \"tool_context\": None,\n",
    "        \"schema_catalog\": schema_catalog\n",
    "    }\n",
    "\n",
    "    result = assistant_graph.invoke(state)\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": result[\"output\"]})\n",
    "    if VERBOSE: print(\"\\n---\\n\")\n",
    "    print(\"Assistant:\", result[\"output\"])\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4 - Final Agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}