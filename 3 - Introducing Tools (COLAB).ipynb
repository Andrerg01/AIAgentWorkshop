{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "16e77bde-7eac-4212-9885-52e3de15c1c1",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "oBoOdQKuhUOK"
      },
      "source": [
        "# Introducing Tools\n",
        "\n",
        "Great! Our chatbot has the basics of inner workings. But that's boring, so let's go and give it some tools! Tools are what differentiates an AI Assistant to an AI Agent.\n",
        "Let's keep it simple for this example, but you can make it as complex as you'd like.\n",
        "\n",
        "Here, we'll define a variable that holds in all of my super secret emails, and the agent will be able to acces that *when it decides it's proper*. That's the magic, the tool is always there, and if the agent feels necessary, it will call on it.\n",
        "\n",
        "---\n",
        "In this module specifically, we'll build an agent that, firstly goes thorugh a `router_agent` and decides on what to do, does it need to access the provided `emails`, or just go straight into a `chat` function?\n",
        "\n",
        "If it decides that it needs to access the `emails`, it will direct the graph to the `email_tool`, which will add the necessary context to the agent state, and then go to chat for the completion of the prompt\n",
        "\n",
        "If not, it just goes straight to the chat and completes the prompt.\n",
        "\n",
        "Let's see how we can do it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c151aa7f-07aa-4e5e-bcea-efe2cbf2f363",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "UYO6EdfphUOQ"
      },
      "source": [
        "## 1 Configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6670fcec-61dc-4fa5-b871-5cb63e1748d4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "T8FjTZcehUOR"
      },
      "source": [
        "### 1.1 Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4a680745-b774-41dd-babb-5f756a6fa625",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IG3k8KBYhUOT",
        "outputId": "6a6fa2a7-872d-4cda-a3b8-958ab5414fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph==0.0.36\n",
            "  Downloading langgraph-0.0.36-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain<0.2.0,>=0.1.20\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.20\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.94.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.20) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.20) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.20) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.20)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2.0,>=0.1.20)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.20)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2.0,>=0.1.20)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2,>=1 (from langchain<0.2.0,>=0.1.20)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.20) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.20) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.20) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.20) (1.33)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.20)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.20) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.20) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.20) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.20) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.20) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.20) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.20) (3.2.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langgraph-0.0.36-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: packaging, numpy, mypy-extensions, typing-inspect, marshmallow, langsmith, dataclasses-json, langchain-core, langgraph, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.4\n",
            "    Uninstalling langsmith-0.4.4:\n",
            "      Successfully uninstalled langsmith-0.4.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.68\n",
            "    Uninstalling langchain-core-0.3.68:\n",
            "      Successfully uninstalled langchain-core-0.3.68\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.8\n",
            "    Uninstalling langchain-text-splitters-0.3.8:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.8\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.26\n",
            "    Uninstalling langchain-0.3.26:\n",
            "      Successfully uninstalled langchain-0.3.26\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-bigquery 3.34.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.2 langgraph-0.0.36 langsmith-0.1.147 marshmallow-3.26.1 mypy-extensions-1.1.0 numpy-1.26.4 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging"
                ]
              },
              "id": "4492973a1f8e42feba380df869fac664"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%pip install \"langgraph==0.0.36\" \"langchain>=0.1.20,<0.2.0\" \"langchain-core>=0.1.20,<0.2.0\" openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "16d85402-6d21-408e-8498-a6f4ba42b4f6",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "YNNmjJn5hUOW"
      },
      "source": [
        "### 1.2 Imports\n",
        "One small difference now is that we'll be importing the `json`. We'll ask the llm to give us an output in JSON format at some point, where we need to interpret into code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b6cb3a22-54f7-45b1-8746-ec357406d458",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "mwGVIjJWhUOY"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from typing import Dict, List, Optional, TypedDict\n",
        "import json\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f56101f5-066b-4fd3-9bef-311f1070e481",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "uCmQKdSehUOZ"
      },
      "source": [
        "### 1.3 Config Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1f5b9ca6-a74f-43a3-a1ae-4e6614deaaf4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "wFYKGDXJhUOa"
      },
      "outputs": [],
      "source": [
        "# Chat Model\n",
        "CHAT_ENDPOINT = \"gpt-4o\"\n",
        "# Instruct Model\n",
        "INSTRUCT_ENDPOINT = \"gpt-4o\"\n",
        "# This is my key, don't abuse it.\n",
        "OPENAI_API_KEY = \"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\"\n",
        "# Global toggle to see hidden outputs\n",
        "VERBOSE = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3214410d-007e-4111-9131-43f1ae27eefc",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "OTytiYZQhUOb"
      },
      "source": [
        "### 1.4 - Mock Data\n",
        "Some fake email data we can play with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a40ea5d2-bbcc-4bc6-ae92-44e5e7e22f2b",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "DNpNazMLhUOc"
      },
      "outputs": [],
      "source": [
        "email_archive = [\n",
        "    {\"sender\": \"bob@example.com\", \"subject\": \"Meeting Notes\", \"body\": \"Project X sync summary.\"},\n",
        "    {\"sender\": \"alice@example.com\", \"subject\": \"Budget\", \"body\": \"Q3 budget is approved.\"},\n",
        "    {\"sender\": \"grandma@snailmail.net\", \"subject\": \"🍪 Fresh Cookies!\", \"body\": \"Just baked your favorite. Come by this weekend or I'll mail them in bubble wrap again.\"},\n",
        "    {\"sender\": \"noreply@catfactsdaily.com\", \"subject\": \"Your Daily Cat Fact 🐱\", \"body\": \"A group of cats is called a clowder.\"},\n",
        "    {\"sender\": \"kevin@adventurebros.org\", \"subject\": \"Camping Trip Checklist\", \"body\": \"Do NOT forget the marshmallows this time.\"},\n",
        "    {\"sender\": \"calendar-bot@work.io\", \"subject\": \"Meeting Overload Alert\", \"body\": \"You have 5 overlapping meetings tomorrow. Good luck.\"},\n",
        "    {\"sender\": \"tina@craftcorner.com\", \"subject\": \"Glue Gun Emergency\", \"body\": \"Do you still have that industrial glue? Mine exploded mid-project.\"},\n",
        "    {\"sender\": \"petpics@pawstagram.com\", \"subject\": \"Scout’s Weekly Report 🐶\", \"body\": \"Scout chased 3 squirrels, destroyed one pillow, and learned to high-five. See attached photos.\"},\n",
        "    {\"sender\": \"mysterygamer123@unknown.com\", \"subject\": \"🎮 You’ve Been Challenged!\", \"body\": \"Beat my high score if you dare. Loser buys pizza.\"},\n",
        "    {\"sender\": \"mom@family.net\", \"subject\": \"Call me!\", \"body\": \"I saw a TikTok about something called 'digital burnout.' Are you ok? Drink water.\"},\n",
        "    {\"sender\": \"team-snackchat@office.com\", \"subject\": \"Emergency Snack Run 🍫\", \"body\": \"We’re out of chocolate. Crisis level: Orange. Send help or snacks.\"},\n",
        "    {\"sender\": \"robot@remind.me\", \"subject\": \"Don’t Forget Your Umbrella ☔\", \"body\": \"Forecast says rain at 3:47 PM. You’re welcome.\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d9c2d7d6-b7db-4569-b5d9-4fb148b3a7a7",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "95j_KiA3hUOe"
      },
      "source": [
        "## 2 Defining Functions and Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "65f71185-8ad8-4ddc-91f3-bf0e33866559",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "EvEZrqxzhUOf"
      },
      "source": [
        "### 2.1 Classes\n",
        "\n",
        "Here, let's change the `AgentState` class a bit:\n",
        " - We need to add a few fields; Let's add a field of available tools, so we can check all the tools we have access to at any point in the graph\n",
        " - We'll aslo add a field called tool_context, for any new context the tools might give that other nodes can take advantage of."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5d38220c-f162-4dd7-bf95-ede57cec55a0",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "mj-SsFfehUOf"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict, total=False):\n",
        "    \"\"\"Conversation state passed between graph nodes.\"\"\"\n",
        "    chat_history: List[Dict[str, str]]   # chat history in OpenAI‑style format\n",
        "    verbose: bool                    # toggle debug prints\n",
        "    output: Optional[str]            # assistant response\n",
        "    ### vvv New Fields vvv\n",
        "    available_tools: Optional[Dict[str, str]]   # names and descriptions of tools the router can pick\n",
        "    tool_context: Optional[str]                 # extra context (cleared each turn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ddd79154-160a-415a-a8ae-e544c0e000f5",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "GTjkYpsyhUOg"
      },
      "source": [
        "### 2.2 - Connection Function\n",
        "\n",
        "This one remains unchanged, nothing new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "62cf2efd-7c7e-4834-9dd5-5a543052d27d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "vzHVnRDNhUOg"
      },
      "outputs": [],
      "source": [
        "def openai_llm(messages, model_endpoint=\"gpt-4o\", verbose=False):\n",
        "    \"\"\"\n",
        "    Calls OpenAI's chat completion endpoint.\n",
        "    Creates and destroys the client inside the function.\n",
        "    Returns the assistant's response as a string.\n",
        "    \"\"\"\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)  # Create the client\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n=== LLM CALL →\", model_endpoint, \" ===\")\n",
        "        for m in messages:\n",
        "            print(f\"{m['role'].upper()}: {m['content']}\")\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_endpoint,\n",
        "        messages=messages,\n",
        "        temperature=0.7,\n",
        "        max_tokens=1000\n",
        "    )\n",
        "\n",
        "    content = response.choices[0].message.content\n",
        "\n",
        "    if verbose: print(\"LLM RESPONSE:\", content[:300] + (\"…\" if len(content) > 300 else \"\"))\n",
        "    if verbose: print(\"=== LLM CALL END ===\")\n",
        "\n",
        "    return content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ba2ddef2-0107-4dc2-ad65-7c71c1b8b309",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "XyGMye8ghUOh"
      },
      "source": [
        "### 2.3 - Defining Agents and Tools as Functions\n",
        "Now we got some changes going.\n",
        "\n",
        "First, our good ol' `chat_agent` will perform one more task. When sending the information to the LLM for a response, it will include all of the values inside tools_context, so that it can make the best informed decision\n",
        "\n",
        "We'll have a few new functions as well\n",
        "\n",
        "`email_tool`\n",
        " - Won't even need to use LLMs here, we'll just have it add all the current emails to the tools context, simple as that. So I'll call it an email_tool, rather than email_agent. If we want to add some intelligence or filtering to it (spoiler), then we can rename it to email_agent. Purely convetion.\n",
        "\n",
        "`router_agent`\n",
        " - For this, we'll send the chat history to a LLM, together with the tool options, and have it return what tool(s) to use, if any. We'll need to format the output nicely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "62e8ac88-957b-4dad-ab6a-83ed14087bde",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "ZBV5weTHhUOh"
      },
      "outputs": [],
      "source": [
        "def router_agent(state):\n",
        "    if state[\"verbose\"]: print(\"\\n--- ROUTER AGENT NODE ---\")\n",
        "\n",
        "    # Build tool list with descriptions\n",
        "    tool_lines = [\n",
        "        f\"- {name}: {desc}\"\n",
        "        for name, desc in (state[\"available_tools\"] or {}).items()\n",
        "    ]\n",
        "    tool_catalog = \"\\n\".join(tool_lines) or \"none\"\n",
        "\n",
        "    # The router agent has its own system prompt\n",
        "    router_system_prompt = (\n",
        "        \"You are an AI router. Choose the single best tool for answering the user's \"\n",
        "        \"latest message.\\n\\n\"\n",
        "        f\"Available tools:\\n{tool_catalog}\\n\\n\"\n",
        "        \"Return ONLY a JSON object like {\\\"tool\\\": \\\"chat\\\"} or {\\\"tool\\\": \\\"email\\\"}.\"\n",
        "    )\n",
        "\n",
        "    # Ignores all system prompts from the chat history\n",
        "    modified_chat_hisotry = [{\"role\": \"system\", \"content\": router_system_prompt}] + [m for m in state[\"chat_history\"] if m[\"role\"] != \"system\"]\n",
        "\n",
        "    # Getting the response from the LLM, should be something like: {\"tool\": \"chat\"}\n",
        "    llm_response = openai_llm(\n",
        "        modified_chat_hisotry,\n",
        "        model_endpoint=INSTRUCT_ENDPOINT, # Using the instruct endpoint\n",
        "        verbose=state[\"verbose\"]\n",
        "    )\n",
        "\n",
        "    # We'll ignore everything that's not in side of \"{}\"\n",
        "    start = llm_response.rfind(\"{\")\n",
        "    end   = llm_response.rfind(\"}\")\n",
        "    decision_json = llm_response[start : end + 1]\n",
        "    decision = json.loads(decision_json)\n",
        "\n",
        "    if state[\"verbose\"]: print(f\"Extracted decision: {decision}\")\n",
        "\n",
        "    # Stash the JSON string in output; graph edges will parse it\n",
        "    state[\"output\"] = json.dumps(decision)\n",
        "\n",
        "    if state[\"verbose\"]: print(\"\\n--- ROUTER AGENT NODE END ---\")\n",
        "\n",
        "    # Returns updated version of state\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e4522128-155a-4d16-a10b-ebd1bcb1bbf3",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "lKV2HX6QhUOh"
      },
      "outputs": [],
      "source": [
        "def email_tool(state):\n",
        "    if state[\"verbose\"]: print(\"\\n--- EMAIL TOOL NODE ---\")\n",
        "\n",
        "    # Neatly format the email archive into a string\n",
        "    context = \"\\n\\n\".join(\n",
        "        f\"\"\"From: {email['sender']}\n",
        "        Subject: {email['subject']}\n",
        "        Body: {email['body']}\"\"\"\n",
        "    for email in email_archive)\n",
        "\n",
        "    if state[\"verbose\"]: print(f\"Email archive context: {context}\")\n",
        "    # Store ONLY in scratch space – do not touch chat history\n",
        "    state[\"tool_context\"] = context\n",
        "    state[\"output\"] = \"email_context_ready\"   # optional status message\n",
        "\n",
        "    if state[\"verbose\"]: print(\"\\n--- EMAIL TOOL NODE END ---\")\n",
        "\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2476844c-abf6-4dae-b9a3-fb3da9f1cefa",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "SdqVdU6XhUOi"
      },
      "outputs": [],
      "source": [
        "# The chat agent will be the same as before, except we'll append the tool context to the chat prompt\n",
        "def chat_agent(state):\n",
        "    if state[\"verbose\"]: print(\"\\n--- CHAT AGENT NODE ---\")\n",
        "\n",
        "    # We'll create a new variable for the chat history. The regular hitory, plut whatever contexts we get from the tools.\n",
        "    appended_chat_history = state[\"chat_history\"] + [{\"role\":\"user\", \"content\":f\"TOOLS CONTEXT:\\n{state['tool_context']}\"}]\n",
        "\n",
        "    reply = openai_llm(\n",
        "        appended_chat_history,\n",
        "        model_endpoint=CHAT_ENDPOINT,\n",
        "        verbose=state[\"verbose\"]\n",
        "    )\n",
        "\n",
        "    state[\"chat_history\"].append({\"role\": \"assistant\", \"content\": reply})\n",
        "    state[\"output\"]   = reply\n",
        "\n",
        "    if state[\"verbose\"]: print(\"\\n--- CHAT AGENT NODE END ---\")\n",
        "\n",
        "    # Returns updated version of state\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ce339cb2-7ff0-47f8-8d43-211c4c38716e",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "MYk__mskhUOi"
      },
      "source": [
        "## 3 Initializing Chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8a6abfcc-9e9b-4187-b2d8-2d40f08918ab",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "ve1XCSswhUOj"
      },
      "source": [
        "### 3.1 - Defining Graph\n",
        "\n",
        "Okay! More complex now... How do we deal with those decisions of the router?\n",
        "\n",
        "Well, that's where the `conditional_edges` come in. Depending on the output of the last node, we'll decide on where to go!\n",
        "\n",
        "Let's go thorugh the code below and see how that unravels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "75e1935b-d494-42e2-9ed6-e9e780ee5c6c",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "ZKqlnJ3JhUOj"
      },
      "outputs": [],
      "source": [
        "# Initializing Graph\n",
        "g = StateGraph(AgentState)\n",
        "\n",
        "# Adding each node, not connected to anything yet\n",
        "g.add_node(\"router_agent\",      RunnableLambda(router_agent))\n",
        "g.add_node(\"email_tool\",        RunnableLambda(email_tool))\n",
        "g.add_node(\"chat_agent\",        RunnableLambda(chat_agent))\n",
        "\n",
        "# Definin entry point, this time it's the router node\n",
        "g.set_entry_point(\"router_agent\")\n",
        "\n",
        "# Decide where to go by inspecting the JSON string in state[\"output\"]\n",
        "def pick_next(state: AgentState) -> str:\n",
        "    return json.loads(state[\"output\"])[\"tool\"]\n",
        "\n",
        "# Since router is conditional, we'll get it's outputs, and decide where the AgentState goes to depending on the output.\n",
        "g.add_conditional_edges(\n",
        "    \"router_agent\",\n",
        "    pick_next,\n",
        "    {\n",
        "        \"chat\":  \"chat_agent\",\n",
        "        \"email\": \"email_tool\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Email tool always hands off to chat\n",
        "g.add_edge(\"email_tool\", \"chat_agent\")\n",
        "g.add_edge(\"chat_agent\", END)\n",
        "\n",
        "assistant_graph = g.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "17ec37b3-d904-4f80-8c64-962f378f872f",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "zhhhkGslhUOj"
      },
      "source": [
        "### 3.2 - Chat Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c451f3a2-2fd7-463d-88de-55fc585990bc",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5EKin5DhUOj",
        "outputId": "e70b7988-9726-4388-a876-0107c397fbc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: Good morning\n",
            "\n",
            "--- ROUTER AGENT NODE ---\n",
            "\n",
            "=== LLM CALL → gpt-4o  ===\n",
            "SYSTEM: You are an AI router. Choose the single best tool for answering the user's latest message.\n",
            "\n",
            "Available tools:\n",
            "- email: Search your recent e-mail archive\n",
            "- chat: Continues on regualar conversation.\n",
            "\n",
            "Return ONLY a JSON object like {\"tool\": \"chat\"} or {\"tool\": \"email\"}.\n",
            "USER: Good morning\n",
            "LLM RESPONSE: {\"tool\": \"chat\"}\n",
            "=== LLM CALL END ===\n",
            "Extracted decision: {'tool': 'chat'}\n",
            "\n",
            "--- ROUTER AGENT NODE END ---\n",
            "\n",
            "--- CHAT AGENT NODE ---\n",
            "\n",
            "=== LLM CALL → gpt-4o  ===\n",
            "SYSTEM: You are a helpful AI Agent. You have access to an email database if needed.\n",
            "USER: Good morning\n",
            "USER: TOOLS CONTEXT:\n",
            "None\n",
            "LLM RESPONSE: Good morning! How can I assist you today?\n",
            "=== LLM CALL END ===\n",
            "\n",
            "--- CHAT AGENT NODE END ---\n",
            "Assistant: Good morning! How can I assist you today?\n",
            "You: Do I have any emails from my family?\n",
            "\n",
            "--- ROUTER AGENT NODE ---\n",
            "\n",
            "=== LLM CALL → gpt-4o  ===\n",
            "SYSTEM: You are an AI router. Choose the single best tool for answering the user's latest message.\n",
            "\n",
            "Available tools:\n",
            "- email: Search your recent e-mail archive\n",
            "- chat: Continues on regualar conversation.\n",
            "\n",
            "Return ONLY a JSON object like {\"tool\": \"chat\"} or {\"tool\": \"email\"}.\n",
            "USER: Good morning\n",
            "ASSISTANT: Good morning! How can I assist you today?\n",
            "USER: Do I have any emails from my family?\n",
            "LLM RESPONSE: {\"tool\": \"email\"}\n",
            "=== LLM CALL END ===\n",
            "Extracted decision: {'tool': 'email'}\n",
            "\n",
            "--- ROUTER AGENT NODE END ---\n",
            "\n",
            "--- EMAIL TOOL NODE ---\n",
            "Email archive context: From: bob@example.com\n",
            "        Subject: Meeting Notes\n",
            "        Body: Project X sync summary.\n",
            "\n",
            "From: alice@example.com\n",
            "        Subject: Budget\n",
            "        Body: Q3 budget is approved.\n",
            "\n",
            "From: grandma@snailmail.net\n",
            "        Subject: 🍪 Fresh Cookies!\n",
            "        Body: Just baked your favorite. Come by this weekend or I'll mail them in bubble wrap again.\n",
            "\n",
            "From: noreply@catfactsdaily.com\n",
            "        Subject: Your Daily Cat Fact 🐱\n",
            "        Body: A group of cats is called a clowder.\n",
            "\n",
            "From: kevin@adventurebros.org\n",
            "        Subject: Camping Trip Checklist\n",
            "        Body: Do NOT forget the marshmallows this time.\n",
            "\n",
            "From: calendar-bot@work.io\n",
            "        Subject: Meeting Overload Alert\n",
            "        Body: You have 5 overlapping meetings tomorrow. Good luck.\n",
            "\n",
            "From: tina@craftcorner.com\n",
            "        Subject: Glue Gun Emergency\n",
            "        Body: Do you still have that industrial glue? Mine exploded mid-project.\n",
            "\n",
            "From: petpics@pawstagram.com\n",
            "        Subject: Scout’s Weekly Report 🐶\n",
            "        Body: Scout chased 3 squirrels, destroyed one pillow, and learned to high-five. See attached photos.\n",
            "\n",
            "From: mysterygamer123@unknown.com\n",
            "        Subject: 🎮 You’ve Been Challenged!\n",
            "        Body: Beat my high score if you dare. Loser buys pizza.\n",
            "\n",
            "From: mom@family.net\n",
            "        Subject: Call me!\n",
            "        Body: I saw a TikTok about something called 'digital burnout.' Are you ok? Drink water.\n",
            "\n",
            "From: team-snackchat@office.com\n",
            "        Subject: Emergency Snack Run 🍫\n",
            "        Body: We’re out of chocolate. Crisis level: Orange. Send help or snacks.\n",
            "\n",
            "From: robot@remind.me\n",
            "        Subject: Don’t Forget Your Umbrella ☔\n",
            "        Body: Forecast says rain at 3:47 PM. You’re welcome.\n",
            "\n",
            "--- EMAIL TOOL NODE END ---\n",
            "\n",
            "--- CHAT AGENT NODE ---\n",
            "\n",
            "=== LLM CALL → gpt-4o  ===\n",
            "SYSTEM: You are a helpful AI Agent. You have access to an email database if needed.\n",
            "USER: Good morning\n",
            "ASSISTANT: Good morning! How can I assist you today?\n",
            "USER: Do I have any emails from my family?\n",
            "USER: TOOLS CONTEXT:\n",
            "From: bob@example.com\n",
            "        Subject: Meeting Notes\n",
            "        Body: Project X sync summary.\n",
            "\n",
            "From: alice@example.com\n",
            "        Subject: Budget\n",
            "        Body: Q3 budget is approved.\n",
            "\n",
            "From: grandma@snailmail.net\n",
            "        Subject: 🍪 Fresh Cookies!\n",
            "        Body: Just baked your favorite. Come by this weekend or I'll mail them in bubble wrap again.\n",
            "\n",
            "From: noreply@catfactsdaily.com\n",
            "        Subject: Your Daily Cat Fact 🐱\n",
            "        Body: A group of cats is called a clowder.\n",
            "\n",
            "From: kevin@adventurebros.org\n",
            "        Subject: Camping Trip Checklist\n",
            "        Body: Do NOT forget the marshmallows this time.\n",
            "\n",
            "From: calendar-bot@work.io\n",
            "        Subject: Meeting Overload Alert\n",
            "        Body: You have 5 overlapping meetings tomorrow. Good luck.\n",
            "\n",
            "From: tina@craftcorner.com\n",
            "        Subject: Glue Gun Emergency\n",
            "        Body: Do you still have that industrial glue? Mine exploded mid-project.\n",
            "\n",
            "From: petpics@pawstagram.com\n",
            "        Subject: Scout’s Weekly Report 🐶\n",
            "        Body: Scout chased 3 squirrels, destroyed one pillow, and learned to high-five. See attached photos.\n",
            "\n",
            "From: mysterygamer123@unknown.com\n",
            "        Subject: 🎮 You’ve Been Challenged!\n",
            "        Body: Beat my high score if you dare. Loser buys pizza.\n",
            "\n",
            "From: mom@family.net\n",
            "        Subject: Call me!\n",
            "        Body: I saw a TikTok about something called 'digital burnout.' Are you ok? Drink water.\n",
            "\n",
            "From: team-snackchat@office.com\n",
            "        Subject: Emergency Snack Run 🍫\n",
            "        Body: We’re out of chocolate. Crisis level: Orange. Send help or snacks.\n",
            "\n",
            "From: robot@remind.me\n",
            "        Subject: Don’t Forget Your Umbrella ☔\n",
            "        Body: Forecast says rain at 3:47 PM. You’re welcome.\n",
            "LLM RESPONSE: Yes, you have two emails from your family:\n",
            "\n",
            "1. From: grandma@snailmail.net  \n",
            "   Subject: 🍪 Fresh Cookies!  \n",
            "   Body: Just baked your favorite. Come by this weekend or I'll mail them in bubble wrap again.\n",
            "\n",
            "2. From: mom@family.net  \n",
            "   Subject: Call me!  \n",
            "   Body: I saw a TikTok about something called…\n",
            "=== LLM CALL END ===\n",
            "\n",
            "--- CHAT AGENT NODE END ---\n",
            "Assistant: Yes, you have two emails from your family:\n",
            "\n",
            "1. From: grandma@snailmail.net  \n",
            "   Subject: 🍪 Fresh Cookies!  \n",
            "   Body: Just baked your favorite. Come by this weekend or I'll mail them in bubble wrap again.\n",
            "\n",
            "2. From: mom@family.net  \n",
            "   Subject: Call me!  \n",
            "   Body: I saw a TikTok about something called 'digital burnout.' Are you ok? Drink water.\n",
            "You: exit\n"
          ]
        }
      ],
      "source": [
        "chat_history = [\n",
        "    {'role': 'system', 'content': 'You are a helpful AI Agent. You have access to an email database if needed.'}\n",
        "]\n",
        "state = AgentState(\n",
        "    chat_history=chat_history,\n",
        "    verbose=VERBOSE,\n",
        "    output=None,\n",
        "    available_tools={\"email\": \"Search your recent e-mail archive\", \"chat\": \"Continues on regualar conversation.\"},\n",
        "    tool_context=None\n",
        ")\n",
        "\n",
        "while True:\n",
        "    # Gets the user's prompt\n",
        "    user_text = input(\"You: \").strip()\n",
        "    # Exit strategy\n",
        "    if user_text == \"exit\":\n",
        "        break\n",
        "\n",
        "    # Append the user's message to the chat history of the state\n",
        "    state[\"chat_history\"].append({\"role\": \"user\", \"content\": user_text})\n",
        "\n",
        "    # Updates the state after going through the graph\n",
        "    state = assistant_graph.invoke(state)\n",
        "\n",
        "    # Resets the tool context once it's not longer needed\n",
        "    state[\"tool_context\"] = None\n",
        "\n",
        "    print(\"Assistant:\", state[\"output\"])"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": {
        "base_environment": "",
        "environment_version": "2"
      },
      "inputWidgetPreferences": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "3 - Introducing Tools",
      "widgets": {}
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}