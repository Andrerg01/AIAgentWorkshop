{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1caee55-e101-40a1-9edd-0d4c072e7ad8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Simple Chat\n",
    "\n",
    "Awesome! We now know how to connect to our LLM and ask stuff from models!\n",
    "\n",
    "Now that we can do basic communication with our LLMs, we'll start on building a complex agent. Let's start with some basic configurations, learning our syntax, and establishing basic communication with an LLM through LangGraph, then we'll complicate it by adding some tools the LLM can take advantage of.\n",
    "\n",
    "Could we build a simple chat without LangGraph? Yes, easily. Could we do the rest of the course without LangGraph? Yes, but not easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d4b0a96-728e-4b55-9090-b4534d00f76b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1 Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c409f44-99ec-4e2a-8605-19ea5ec8520c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.1 Installs\n",
    "\n",
    " - `langgraph==0.0.36` – the graph engine that lets us wire nodes together into a stateful workflow.\n",
    "\n",
    " - `langchain (≥ 0.1.20 < 0.2.0)` – full LangChain toolkit (agents, tools, retrievers). We’ll lean on it as we grow the course.\n",
    "\n",
    " - `langchain-core (≥ 0.1.20 < 0.2.0)` – the lightweight “interfaces-only” slice of LangChain. Gives us the Runnable abstraction without all the heavy extras.\n",
    "\n",
    " - `requests` – dead-simple HTTP client. We use it once to hit the Databricks serving endpoint.\n",
    "\n",
    "After installing, we restart the kernel (dbutils.library.restartPython()) so the freshly-added packages are importable in the same notebook session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28d0584b-eb99-4c67-8f00-732ff6fb3f5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph==0.0.36\n  Downloading langgraph-0.0.36-py3-none-any.whl.metadata (44 kB)\nCollecting langchain<0.2.0,>=0.1.20\n  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\nCollecting langchain-core<0.2.0,>=0.1.20\n  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (2.31.0)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (6.0)\nCollecting SQLAlchemy<3,>=1.4 (from langchain<0.2.0,>=0.1.20)\n  Downloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nCollecting aiohttp<4.0.0,>=3.8.3 (from langchain<0.2.0,>=0.1.20)\n  Downloading aiohttp-3.12.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\nCollecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.20)\n  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\nCollecting langchain-community<0.1,>=0.0.38 (from langchain<0.2.0,>=0.1.20)\n  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.20)\n  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2.0,>=0.1.20)\n  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (1.23.5)\nRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (1.10.6)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (8.2.2)\nCollecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.20)\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: packaging<24.0,>=23.2 in /databricks/python3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.20) (23.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests) (2023.7.22)\nCollecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20)\n  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\nCollecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20)\n  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\nCollecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20)\n  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\nCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20)\n  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nCollecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20)\n  Downloading multidict-6.6.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\nCollecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20)\n  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20)\n  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\nCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20)\n  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20)\n  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.20)\n  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\nCollecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20)\n  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20)\n  Downloading orjson-3.10.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\nCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.20) (4.10.0)\nCollecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.20)\n  Downloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\nCollecting anyio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20)\n  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\nCollecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20)\n  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\nCollecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20)\n  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20) (0.4.3)\nCollecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20)\n  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\nDownloading langgraph-0.0.36-py3-none-any.whl (56 kB)\nDownloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m28.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\nDownloading aiohttp-3.12.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.7 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m52.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\nDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m71.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\nDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\nDownloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m70.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\nDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\nDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\nDownloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\nDownloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (585 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/585.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m585.5/585.5 kB\u001B[0m \u001B[31m28.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\nDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\nDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\nDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\nDownloading multidict-6.6.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\nDownloading orjson-3.10.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\nDownloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\nDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\nDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nDownloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\nDownloading anyio-4.9.0-py3-none-any.whl (100 kB)\nDownloading h11-0.16.0-py3-none-any.whl (37 kB)\nDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\nInstalling collected packages: typing-inspect, sniffio, propcache, orjson, multidict, marshmallow, jsonpointer, h11, greenlet, frozenlist, attrs, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, jsonpatch, httpcore, dataclasses-json, anyio, aiosignal, httpx, aiohttp, langsmith, langchain-core, langgraph, langchain-text-splitters, langchain-community, langchain\nSuccessfully installed SQLAlchemy-2.0.41 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 anyio-4.9.0 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.7.0 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.2 langgraph-0.0.36 langsmith-0.1.147 marshmallow-3.26.1 multidict-6.6.3 orjson-3.10.18 propcache-0.3.2 requests-toolbelt-1.0.0 sniffio-1.3.1 typing-inspect-0.9.0 yarl-1.20.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install \"langgraph==0.0.36\" \"langchain>=0.1.20,<0.2.0\" \"langchain-core>=0.1.20,<0.2.0\" requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6eccc0d-19d9-4070-8a41-ee2be4c041ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mWarning: statements after `dbutils.library.restartPython()` will execute before Python is restarted.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "dbutils.library.restartPython() # Necessary for clearing cache and whatnots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f58dc9b-e566-4689-906e-d1880eea4604",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.2 Imports\n",
    "\n",
    " - from `langgraph.graph import StateGraph, END`\n",
    "   - `StateGraph` – build and compile our node graph.\n",
    "   - `END` – sentinel that tells LangGraph where to stop.\n",
    "\n",
    " - `from langchain_core.runnables import RunnableLambda` – wraps a normal Python function so the graph can call it like any other LangChain “runnable.”\n",
    "\n",
    " - `from typing import Dict, List, Optional, TypedDict` – creates AgentState, a typed dictionary that documents (and type-checks) the keys we pass between nodes.\n",
    "\n",
    " - `import requests` – actually makes the REST call to Databricks inside databricks_llm().\t\n",
    "\n",
    " - `import textwrap` – trims long chat messages when `VERBOSE=True` so console logs stay readable.\n",
    "\n",
    " - `import json` – handy for future pretty-printing / logging of payloads (not strictly required yet).\n",
    "\n",
    " - `import datetime` – included for quick timestamping if you decide to log anything; safe to remove if you don’t need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdb893fa-d502-4bc1-82fd-212bd0c1fd1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing import Dict, List, Optional, TypedDict\n",
    "import requests\n",
    "import json\n",
    "import textwrap\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f53b3e5c-8e1f-4a75-a391-c2659bd28a25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.3 Config Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "331e806a-3637-47ba-aae1-3b9012cb704e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CHAT_ENDPOINT = \"databricks-llama-4-maverick\" # Chat Model\n",
    "INSTRUCT_ENDPOINT = \"databricks-meta-llama-3-1-8b-instruct\" # Instruct Model\n",
    "DATABRICKS_URL = \"https://dbc-864a442b-39b8.cloud.databricks.com\" # The Base URL at the top\n",
    "DATABRICKS_TOKEN = \"dapi763c08facfcf240733ac46730443c6cf\" # Your own token\n",
    "VERBOSE = True  # global toggle to see hidden outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfbfada0-36c9-4ed9-9ca2-72961ea73a93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2 Defining Functions and Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa34b46c-e292-46cb-af70-3cdb237cdb03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.1 Classes\n",
    "\n",
    "Now here we'll see one of the most important classes so far, the AgentState (call it whatever you'd like, ChatState, ChatFlow, State, whatever, I like AgentState).\n",
    "\n",
    "As we travel through the nodes of our complex agent, this state will carry information around. It's necessary for the LangGraph setup.\n",
    "\n",
    "On the example below, no matter where we are in the logic, the node will have access to the chat history (messages), verbosity (for our sake), and the output from the last node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07a00e8f-b52b-4559-a947-e3a8073c6998",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict, total=False):\n",
    "    \"\"\"Conversation state passed between graph nodes.\"\"\"\n",
    "    messages: List[Dict[str, str]]   # chat history in OpenAI‑style format\n",
    "    verbose: bool                    # toggle debug prints\n",
    "    output: Optional[str]            # assistant response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ceb25bb3-e675-4c97-9cc2-5384cdcaaccd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2 - Connection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab6df9d7-630b-4331-a610-dd2199045c37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The databricks function we know well. I added some type restrictions so there's no confusion, but that's not\n",
    "def databricks_llm(messages: List[Dict[str, str]], *, model_endpoint: str = CHAT_ENDPOINT, verbose: bool = False) -> str:\n",
    "    \"\"\"Call a Databricks serving endpoint that follows the OpenAI chat format.\"\"\"\n",
    "    if verbose:\n",
    "        print(\"\\n=== LLM CALL →\", model_endpoint)\n",
    "        for m in messages:\n",
    "            print(f\"{m['role'].upper()}: {textwrap.shorten(m['content'], width=120)}\")\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {DATABRICKS_TOKEN}\",\n",
    "        \"Content-Type\":  \"application/json\"\n",
    "    }\n",
    "    body = {\n",
    "        \"messages\":   messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\":  1000\n",
    "    }\n",
    "\n",
    "    resp = requests.post(f\"{DATABRICKS_URL}/serving-endpoints/{model_endpoint}/invocations\", headers=headers, json=body)\n",
    "    resp.raise_for_status()\n",
    "    content = resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"LLM RESPONSE:\", content[:300] + (\"…\" if len(content) > 300 else \"\"))\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd0730cb-acbe-4339-aec8-57fdc1626de2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.3 - Defining Agents and Tools as Functions\n",
    "At this point we'd define all the different tools and agents. But of course, right now we only have one agent, so it'll be simple.\n",
    "\n",
    "The agent below is expressed as a function. It takes in the AgentSate (as all tools and agents will). Sends it to the LLM, gets the response, updates the chat history, and returns the agent state again, but with the updates values for messages and output. That simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf9fd0f5-29e4-458b-a96c-928d3a63bd17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def chat_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Takes current state, appends assistant reply, and returns updated state.\"\"\"\n",
    "    if state.get(\"verbose\"):\n",
    "        print(\"\\n--- CHAT AGENT NODE ---\")\n",
    "\n",
    "    reply = databricks_llm(\n",
    "        state[\"messages\"],\n",
    "        model_endpoint=CHAT_ENDPOINT,\n",
    "        verbose=state.get(\"verbose\", False)\n",
    "    )\n",
    "\n",
    "    updated_history = state[\"messages\"] + [{\"role\": \"assistant\", \"content\": reply}]\n",
    "\n",
    "    return {\n",
    "        \"output\":   reply,\n",
    "        \"messages\": updated_history\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a16ba96-5ec1-4d83-8752-22c1b6cac386",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3 Initializing Simple Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce235b19-58f4-4bf2-a8d1-acebe9157a26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.1 - Defining Graph\n",
    "\n",
    "Here we'll define how the graph of all of our agents and tools is connected. Very simple in this case.\n",
    "\n",
    "An graph always needs one `entry point`, and `nodes`, all connected by `edges`. and (at least one) `END`\n",
    "\n",
    " - `entry_point`: Defines which node runs first when the graph is invoked.\n",
    " - `edge`: An edge says “when node A finishes, send the state to node B.”\n",
    " - `node`: A node is any function (or Runnable) that takes an AgentState and returns an updated version of it.\n",
    " - `END`: This means: when chat_agent() finishes, stop the graph here. `END` is not a node, but a signal that execution halts\n",
    "\n",
    "In our case, we have one `node`, one `edge`, and one `END`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1802d2e0-3ba3-4927-97af-4634c5972ddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing a graph with the Agent State\n",
    "g = StateGraph(AgentState)\n",
    "# Define a node for out chat agent, which will run the chat_agent function, we're not defining how it connects to anything yet.\n",
    "g.add_node(\"chat_agent\", RunnableLambda(chat_agent))\n",
    "# Tell the graph what's the first node to run, in this case it's the chat_agent\n",
    "g.set_entry_point(\"chat_agent\")\n",
    "# Tell the graph that once the chat_agent node is done running, end it.\n",
    "g.add_edge(\"chat_agent\", END)\n",
    "\n",
    "# Compiles the graph together\n",
    "simple_chat = g.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40a040d8-590f-4713-9a8c-fb9d7b2018a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2 - Basic Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4397e75c-b8cf-4efe-8d65-07abc71c8e08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  Good morning!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick\nUSER: Good morning!\nLLM RESPONSE: Good morning! I hope you're having a great start to your day. Is there something I can help you with or would you like to chat?\nAssistant: Good morning! I hope you're having a great start to your day. Is there something I can help you with or would you like to chat?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  exit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick\nUSER: Good morning!\nASSISTANT: Good morning! I hope you're having a great start to your day. Is there something I can help you with or would you [...]\nUSER: exit\nLLM RESPONSE: It was nice chatting with you. Feel free to come back and talk to me anytime. Have a great day!\nAssistant: It was nice chatting with you. Feel free to come back and talk to me anytime. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "user_text = \"\"\n",
    "while user_text != 'exit':\n",
    "    user_text = input(\"You: \").strip()\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_text})\n",
    "    # state: AgentState = {\"messages\": chat_history, \"verbose\": VERBOSE, \"output\": None}\n",
    "    state = {\"messages\": chat_history,\n",
    "             \"verbose\": VERBOSE,\n",
    "             \"output\": None}\n",
    "    result = simple_chat.invoke(state)\n",
    "    assistant_reply = result[\"output\"]\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "\n",
    "    print(\"Assistant:\", assistant_reply)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2 - Simple Chat",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}