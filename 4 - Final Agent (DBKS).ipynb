{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d13ad2c0-4d25-4995-8c92-707e37746405",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Final Agent\n",
    "Okay, now we're cooking. Our agent can access some data, that's super cool! But it's not the best now, is it? It can access data, but it loads the ENTIRE dataset into the chat! That's not practical. Especially if our dataset as very large.\n",
    "\n",
    "What we'll do next is to QUERY data SMARTLY! We'll have agents write the SQL to query our data for us. And that will be the final form of our agent.\n",
    "\n",
    "---\n",
    "\n",
    "In this module, we'll make up some large mock dataset, and have the agent query from that as necessary with the SQL query that seems appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebb22fce-9432-49cd-8ea0-f74ccffd2114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1 Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8896e393-f1f3-4cc1-a1c9-6f457cf66d6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.1 Installs\n",
    "We'll be installig `duckdb` so we can do sql queries on pandas dataframes, again, educational purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7e71382-850b-49fc-8715-30212b261580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph==0.0.36 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (0.0.36)\nRequirement already satisfied: langchain<0.2.0,>=0.1.20 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (0.1.20)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.20 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (0.1.53)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (2.31.0)\nRequirement already satisfied: duckdb in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (1.3.2)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (2.0.41)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (3.12.14)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.6.7)\nRequirement already satisfied: langchain-community<0.1,>=0.0.38 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.0.38)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.0.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.1.147)\nRequirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (1.23.5)\nRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (1.10.6)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (8.2.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.20) (1.33)\nRequirement already satisfied: packaging<24.0,>=23.2 in /databricks/python3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.20) (23.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests) (2023.7.22)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.20) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (3.11.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (1.0.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.20) (4.10.0)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.20) (3.2.3)\nRequirement already satisfied: anyio in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (0.16.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20) (0.4.3)\nRequirement already satisfied: sniffio>=1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7a11c6cd-7686-4155-ac58-f660368637e9/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (1.3.1)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install \"langgraph==0.0.36\" \"langchain>=0.1.20,<0.2.0\" \"langchain-core>=0.1.20,<0.2.0\" requests duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34b1db82-c78b-4985-a911-cf3cc44c58c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mWarning: statements after `dbutils.library.restartPython()` will execute before Python is restarted.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "dbutils.library.restartPython() # Necessary for clearing cache and whatnots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18fe56eb-8be0-40b3-ab9f-36a65398d879",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.2 Imports\n",
    "Importing `pandas`, `pandassql`, and `numpy` to generate and query the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ef9f677-768b-4478-9c0e-c430aa8c63d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing import Dict, List, Optional, TypedDict\n",
    "import requests, json, textwrap, datetime\n",
    "import pandas as pd # <-- New Import\n",
    "import duckdb       # <-- New Import\n",
    "import numpy as np  # <-- New Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71a4a451-5fd3-478e-adf2-3575d9a2ecf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.3 Config Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "260807c5-2d26-449d-93bf-cca653d7ecbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Chat Model.\n",
    "CHAT_ENDPOINT = \"databricks-llama-4-maverick\"\n",
    "# Instruct Model.\n",
    "INSTRUCT_ENDPOINT = \"databricks-meta-llama-3-1-8b-instruct\" \n",
    "# The Base URL at the top, this is my URL, it won't work for you.\n",
    "DATABRICKS_URL = \"https://dbc-864a442b-39b8.cloud.databricks.com\" \n",
    "# Your own token, to get this, to to your prfile (top right) -> Settings -> Developer -> Access Tokens (Manage) -> Generate new token.\n",
    "DATABRICKS_TOKEN = \"<MY_DATABRICKS_TOKEN>\" \n",
    "# This is my token, it won't work for you.\n",
    "DATABRICKS_TOKEN = \"dapi763c08facfcf240733ac46730443c6cf\"\n",
    "\n",
    "# Global toggle to see hidden debugging outputs\n",
    "VERBOSE = True  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1babf213-37d5-4901-8ae0-4f122d9d1ce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.4 - Mock Data\n",
    "Some fake sales data we can play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "670a32f0-ede8-46c2-8bb2-4d02b692e7e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The President of the United States</td>\n",
       "      <td>Jet Engine</td>\n",
       "      <td>36</td>\n",
       "      <td>791.771551</td>\n",
       "      <td>2024-01-01 00:00:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VolksWagen</td>\n",
       "      <td>Jet Engine</td>\n",
       "      <td>28</td>\n",
       "      <td>431.421164</td>\n",
       "      <td>2024-01-01 08:46:07.567567567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blockbuster</td>\n",
       "      <td>Cookies</td>\n",
       "      <td>82</td>\n",
       "      <td>872.171541</td>\n",
       "      <td>2024-01-01 17:32:15.135135135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carl</td>\n",
       "      <td>Cookies</td>\n",
       "      <td>91</td>\n",
       "      <td>469.004449</td>\n",
       "      <td>2024-01-02 02:18:22.702702702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VolksWagen</td>\n",
       "      <td>Fake Promises</td>\n",
       "      <td>24</td>\n",
       "      <td>301.048121</td>\n",
       "      <td>2024-01-02 11:04:30.270270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Carl</td>\n",
       "      <td>Jet Engine</td>\n",
       "      <td>74</td>\n",
       "      <td>966.105294</td>\n",
       "      <td>2024-12-29 12:55:29.729729728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>VolksWagen</td>\n",
       "      <td>Jet Engine</td>\n",
       "      <td>44</td>\n",
       "      <td>99.508595</td>\n",
       "      <td>2024-12-29 21:41:37.297297296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Grandma's Cookies</td>\n",
       "      <td>Enriched Uranium</td>\n",
       "      <td>75</td>\n",
       "      <td>979.062153</td>\n",
       "      <td>2024-12-30 06:27:44.864864864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Carl</td>\n",
       "      <td>Cookies</td>\n",
       "      <td>11</td>\n",
       "      <td>105.744224</td>\n",
       "      <td>2024-12-30 15:13:52.432432432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The President of the United States</td>\n",
       "      <td>Dirt</td>\n",
       "      <td>20</td>\n",
       "      <td>857.309639</td>\n",
       "      <td>2024-12-31 00:00:00.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 client  ...                          date\n",
       "0    The President of the United States  ... 2024-01-01 00:00:00.000000000\n",
       "1                            VolksWagen  ... 2024-01-01 08:46:07.567567567\n",
       "2                           Blockbuster  ... 2024-01-01 17:32:15.135135135\n",
       "3                                  Carl  ... 2024-01-02 02:18:22.702702702\n",
       "4                            VolksWagen  ... 2024-01-02 11:04:30.270270270\n",
       "..                                  ...  ...                           ...\n",
       "995                                Carl  ... 2024-12-29 12:55:29.729729728\n",
       "996                          VolksWagen  ... 2024-12-29 21:41:37.297297296\n",
       "997                   Grandma's Cookies  ... 2024-12-30 06:27:44.864864864\n",
       "998                                Carl  ... 2024-12-30 15:13:52.432432432\n",
       "999  The President of the United States  ... 2024-12-31 00:00:00.000000000\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_up_mock_data(n = 1000):\n",
    "    clients = [\"Grandma's Cookies\", \"VolksWagen\", \"The President of the United States\", \"Carl\", \"Blockbuster\"]\n",
    "    products = [\"Cookies\", \"Jet Engine\", \"Enriched Uranium\", \"Dirt\", \"Fake Promises\"]\n",
    "    df = pd.DataFrame({\n",
    "        \"client\": np.random.choice(clients, n),\n",
    "        \"product\": np.random.choice(products, n),\n",
    "        \"quantity\": np.random.randint(0, 100, n),\n",
    "        # Float between 0 and 1000\n",
    "        \"price\": np.random.rand(n) * 1000,\n",
    "        \"date\": pd.date_range(start=\"2024-01-01\", end=\"2024-12-31\", periods=n)\n",
    "    })\n",
    "    return df\n",
    "sales_data = make_up_mock_data(1000)\n",
    "\n",
    "schema_catalog = {\n",
    "    \"sales_data\": (\n",
    "        \"The 'sales_data' table has the following columns:\\n\"\n",
    "        \"- client (string): the customer name\\n\"\n",
    "        \"- product (string): the item sold\\n\"\n",
    "        \"- quantity (int): number of units sold\\n\"\n",
    "        \"- price (float): price per unit\\n\"\n",
    "        \"- date (datetime): date of transaction\\n\"\n",
    "    )\n",
    "}\n",
    "\n",
    "sales_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "263300b2-ca2b-4de8-84c4-e9ab14276fcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2 Defining Functions and Classes\n",
    "\n",
    "Now here we'll change some things. \n",
    "\n",
    "The AgentState will include a new field called `schema_catalog`, so that any node can look at the data catalog and know its organized.\n",
    "\n",
    "Instead of the router routing the state to a tool, it will route it to another agent (`sales_data_agent`), which will look at the state, and write a proper SQL query to use against the data, and send it to the `sales_data_tool` to apply it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6078bd8-a629-426a-874f-af147ccf9180",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.1 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2143af1-b6d2-4907-b1b8-10ff973e2a1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict, total=False):\n",
    "    \"\"\"Conversation state passed between graph nodes.\"\"\"\n",
    "    chat_history: List[Dict[str, str]]   # chat history in OpenAI‑style format\n",
    "    verbose: bool                    # toggle debug prints\n",
    "    output: Optional[str]            # assistant response\n",
    "    available_tools: Optional[Dict[str, str]]   # names and descriptions of tools the router can pick\n",
    "    tool_context: Optional[str]                 # extra context (cleared each turn)\n",
    "    schema_catalog: Optional[Dict[str, str]]    # catalog of schemas and their descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48e96563-7f84-4528-bd56-af94419f9069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2 - Connection Function\n",
    "\n",
    "This one remains unchanged, nothing new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c63752c4-ff29-4a86-ad42-c169c5f3f81f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def databricks_llm(chat_history, model_endpoint, verbose=False):\n",
    "    \"\"\"Call a Databricks serving endpoint that follows the OpenAI chat format.\"\"\"\n",
    "    if verbose:\n",
    "        print(\"\\n=== LLM CALL →\", model_endpoint, \"===\")\n",
    "        for m in chat_history:\n",
    "            print(f\"{m['role'].upper()}: {m['content']}\")\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {DATABRICKS_TOKEN}\",\n",
    "        \"Content-Type\":  \"application/json\"\n",
    "    }\n",
    "    body = {\n",
    "        \"messages\":   chat_history,\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\":  1000\n",
    "    }\n",
    "\n",
    "    resp = requests.post(f\"{DATABRICKS_URL}/serving-endpoints/{model_endpoint}/invocations\", headers=headers, json=body)\n",
    "    resp.raise_for_status()\n",
    "    content = resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    if verbose: print(\"LLM RESPONSE:\", content[:300] + (\"…\" if len(content) > 300 else \"\"))\n",
    "    if verbose: print(\"=== LLM CALL END ===\")\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465f70ad-123f-4649-99a9-9f2795eba3a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.3 - Defining Agents and Tools as Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db84536f-4de6-457e-9871-981030916523",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def router_agent(state: AgentState) -> AgentState:\n",
    "    if state[\"verbose\"]: print(\"\\n--- ROUTER AGENT NODE ---\")\n",
    "\n",
    "    # Build tool list with descriptions\n",
    "    tool_lines = [\n",
    "        f\"- {name}: {desc}\"\n",
    "        for name, desc in (state[\"available_tools\"] or {}).items()\n",
    "    ]\n",
    "    tool_catalog = \"\\n\".join(tool_lines) or \"none\"\n",
    "\n",
    "    # The router agent has its own system prompt\n",
    "    router_system_prompt = (\n",
    "        \"You are an AI router. Choose the single best tool for answering the user's latest message.\\n\\n\"\n",
    "        f\"Available tools:\\n{tool_catalog}\\n\\n\"\n",
    "        \"Return ONLY a JSON object like {\\\"tool\\\": \\\"chat\\\"} or {\\\"tool\\\": \\\"sales_data\\\"}.\"\n",
    "    )\n",
    "\n",
    "    # Ignores all system prompts from the chat history\n",
    "    modified_chat_hisotry = [{\"role\": \"system\", \"content\": router_system_prompt}] + [m for m in state[\"chat_history\"] if m[\"role\"] != \"system\"]\n",
    "\n",
    "    # Getting the response from the LLM, should be something like: {\"tool\": \"chat\"}\n",
    "    llm_response = databricks_llm(\n",
    "        modified_chat_hisotry,\n",
    "        model_endpoint=INSTRUCT_ENDPOINT, # Using the instruct endpoint\n",
    "        verbose=state[\"verbose\"]\n",
    "    )\n",
    "\n",
    "    start = llm_response.rfind(\"{\")\n",
    "    end = llm_response.rfind(\"}\")\n",
    "    decision_json = llm_response[start:end + 1]\n",
    "    decision = json.loads(decision_json)\n",
    "\n",
    "    if state[\"verbose\"]: print(f\"Extracted decision: {decision}\")\n",
    "\n",
    "    # Stash the JSON string in output; graph edges will parse it\n",
    "    state[\"output\"] = json.dumps(decision)\n",
    "\n",
    "    if state[\"verbose\"]: print(\"\\n--- ROUTER AGENT NODE END ---\")\n",
    "\n",
    "    # Returns updated version of state\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "764f864e-06b0-47f8-b9ea-0b2674b25143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sales_data_agent(state):\n",
    "    if state[\"verbose\"]: print(\"\\n--- SALES DATA AGENT NODE ---\")\n",
    "\n",
    "    schema = state[\"schema_catalog\"][\"sales_data\"]\n",
    "\n",
    "    sales_system_prompt = (\n",
    "        \"You are an assistant that writes SQL queries to analyze sales data.\\n\\n\"\n",
    "        f\"{schema}\\n\\n\"\n",
    "        \"Based on the conversation below, write a SQL query that answers the user's request.\\n\"\n",
    "        \"Respond with ONLY the query, wrapped like this:\\n\"\n",
    "        \"```sql\\nSELECT ...\\n```\"\n",
    "    )\n",
    "\n",
    "    # Ignores all system prompts from the chat history\n",
    "    modified_chat_hisotry = [{\"role\": \"system\", \"content\": sales_system_prompt}] + [m for m in state[\"chat_history\"] if m[\"role\"] != \"system\"]\n",
    "\n",
    "    llm_response = databricks_llm(\n",
    "        modified_chat_hisotry,\n",
    "        model_endpoint=CHAT_ENDPOINT,\n",
    "        verbose=state.get(\"verbose\", False),\n",
    "    )\n",
    "\n",
    "    start = llm_response.find(\"```\")\n",
    "    end = llm_response.rfind(\"```\")\n",
    "    sql = llm_response[start + 3:end].strip()\n",
    "    if sql.lower().startswith(\"sql\"):\n",
    "        sql = sql[3:].strip()\n",
    "\n",
    "    if state[\"verbose\"]: print(\"Generated SQL:\\n\", sql)\n",
    "\n",
    "    state[\"output\"] = sql\n",
    "\n",
    "    if state[\"verbose\"]: print(\"\\n--- SALES DATA AGENT NODE END ---\")\n",
    "\n",
    "    # Returns updated version of state\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83a516b8-589f-40c3-a5dd-96f701d28d31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sales_data_tool(state):\n",
    "    if state[\"verbose\"]:print(\"\\n--- SALES DATA TOOL NODE ---\")\n",
    "\n",
    "    query = state[\"output\"]\n",
    "\n",
    "    if state[\"verbose\"]: print(\"Executing SQL with DuckDB:\\n\", query)\n",
    "        \n",
    "    # run against the in-memory DataFrame\n",
    "    result_df = duckdb.query_df(sales_data, \"sales_data\", query).to_df()\n",
    "    context = result_df.to_string(index=False)\n",
    "\n",
    "    state[\"tool_context\"] = context\n",
    "    state[\"output\"]       = context\n",
    "\n",
    "    if state[\"verbose\"]:  print(\"SQL result:\\n\", context)\n",
    "\n",
    "    if state[\"verbose\"]: print(\"\\n--- SALES DATA TOOL NODE END ---\")\n",
    "\n",
    "    # Returns updated version of state\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44c1c4a7-0477-4f63-9cd4-4179cf57b809",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The chat agent will be the same as before\n",
    "def chat_agent(state):\n",
    "    if state[\"verbose\"]: print(\"\\n--- CHAT AGENT NODE ---\")\n",
    "\n",
    "    # We'll create a new variable for the chat history. The regular hitory, plut whatever contexts we get from the tools.\n",
    "    appended_chat_history = state[\"chat_history\"] + [{\"role\":\"user\", \"content\":f\"TOOLS CONTEXT:\\n{state['tool_context']}\"}]\n",
    "\n",
    "    reply = databricks_llm(\n",
    "        appended_chat_history,\n",
    "        model_endpoint=CHAT_ENDPOINT,\n",
    "        verbose=state[\"verbose\"]\n",
    "    )\n",
    "\n",
    "    state[\"chat_history\"].append({\"role\": \"assistant\", \"content\": reply})\n",
    "    state[\"output\"]   = reply\n",
    "\n",
    "    if state[\"verbose\"]: print(\"\\n--- CHAT AGENT NODE END ---\")\n",
    "\n",
    "    # Returns updated version of state\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cae5deba-811e-4b9c-8792-ab1f66a1cb92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3 Initializing Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c71e87a-e2a1-435a-92be-5e5a9bd5df84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.1 - Defining Graph\n",
    "\n",
    "Similar logic as last time, but now we'll connect the `sales_data_agent` to `sales_data_tool`, which will then go to `chat_agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "531e03e1-383f-473a-aef7-489621b613ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "g = StateGraph(AgentState)\n",
    "\n",
    "g.add_node(\"router_agent\", RunnableLambda(router_agent))\n",
    "g.add_node(\"sales_data_agent\", RunnableLambda(sales_data_agent))\n",
    "g.add_node(\"sales_data_tool\", RunnableLambda(sales_data_tool))\n",
    "g.add_node(\"chat_agent\", RunnableLambda(chat_agent))\n",
    "\n",
    "g.set_entry_point(\"router_agent\")\n",
    "\n",
    "def pick_next(state: AgentState) -> str:\n",
    "    return json.loads(state[\"output\"])[\"tool\"]\n",
    "\n",
    "g.add_conditional_edges(\n",
    "    \"router_agent\",\n",
    "    pick_next,\n",
    "    {\n",
    "        \"chat\": \"chat_agent\",\n",
    "        \"sales_data\": \"sales_data_agent\"\n",
    "    },\n",
    ")\n",
    "\n",
    "g.add_edge(\"sales_data_agent\", \"sales_data_tool\")\n",
    "g.add_edge(\"sales_data_tool\", \"chat_agent\")\n",
    "g.add_edge(\"chat_agent\", END)\n",
    "\n",
    "assistant_graph = g.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ae6c8d5-bde1-4b46-bf68-9c23934d25ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2 - Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6230e997-143e-4aa7-ad01-132ea2aa80ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  Good morning"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- ROUTER AGENT NODE ---\n\n=== LLM CALL → databricks-meta-llama-3-1-8b-instruct ===\nSYSTEM: You are an AI router. Choose the single best tool for answering the user's latest message.\n\nAvailable tools:\n- chat: Continue the conversation naturally\n- sales_data: Query the internal sales database using SQL\n\nReturn ONLY a JSON object like {\"tool\": \"chat\"} or {\"tool\": \"sales_data\"}.\nUSER: Good morning\nLLM RESPONSE: {\"tool\": \"chat\"}\n=== LLM CALL END ===\nExtracted decision: {'tool': 'chat'}\n\n--- ROUTER AGENT NODE END ---\n\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick ===\nSYSTEM: You are a helpful AI Agent. You have access to sales data if needed.\nUSER: Good morning\nUSER: TOOLS CONTEXT:\nNone\nLLM RESPONSE: Good morning! How can I help you today?\n=== LLM CALL END ===\n\n--- CHAT AGENT NODE END ---\nAssistant: Good morning! How can I help you today?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  What are all my clients in my database?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- ROUTER AGENT NODE ---\n\n=== LLM CALL → databricks-meta-llama-3-1-8b-instruct ===\nSYSTEM: You are an AI router. Choose the single best tool for answering the user's latest message.\n\nAvailable tools:\n- chat: Continue the conversation naturally\n- sales_data: Query the internal sales database using SQL\n\nReturn ONLY a JSON object like {\"tool\": \"chat\"} or {\"tool\": \"sales_data\"}.\nUSER: Good morning\nASSISTANT: Good morning! How can I help you today?\nUSER: What are all my clients in my database?\nLLM RESPONSE: {\"tool\": \"sales_data\"}\n=== LLM CALL END ===\nExtracted decision: {'tool': 'sales_data'}\n\n--- ROUTER AGENT NODE END ---\n\n--- SALES DATA AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick ===\nSYSTEM: You are an assistant that writes SQL queries to analyze sales data.\n\nThe 'sales_data' table has the following columns:\n- client (string): the customer name\n- product (string): the item sold\n- quantity (int): number of units sold\n- price (float): price per unit\n- date (datetime): date of transaction\n\n\nBased on the conversation below, write a SQL query that answers the user's request.\nRespond with ONLY the query, wrapped like this:\n```sql\nSELECT ...\n```\nUSER: Good morning\nASSISTANT: Good morning! How can I help you today?\nUSER: What are all my clients in my database?\nLLM RESPONSE: ```sql\nSELECT DISTINCT client FROM sales_data;\n```\n=== LLM CALL END ===\nGenerated SQL:\n SELECT DISTINCT client FROM sales_data;\n\n--- SALES DATA AGENT NODE END ---\n\n--- SALES DATA TOOL NODE ---\nExecuting SQL with DuckDB:\n SELECT DISTINCT client FROM sales_data;\nSQL result:\n                             client\n                              Carl\nThe President of the United States\n                        VolksWagen\n                       Blockbuster\n                 Grandma's Cookies\n\n--- SALES DATA TOOL NODE END ---\n\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick ===\nSYSTEM: You are a helpful AI Agent. You have access to sales data if needed.\nUSER: Good morning\nASSISTANT: Good morning! How can I help you today?\nUSER: What are all my clients in my database?\nUSER: TOOLS CONTEXT:\n                            client\n                              Carl\nThe President of the United States\n                        VolksWagen\n                       Blockbuster\n                 Grandma's Cookies\nLLM RESPONSE: It looks like I have access to your client database. According to the data, your clients are:\n\n1. Carl\n2. The President of the United States\n3. VolksWagen\n4. Blockbuster\n5. Grandma's Cookies\n\nIs there anything specific you'd like to know or do with this information?\n=== LLM CALL END ===\n\n--- CHAT AGENT NODE END ---\nAssistant: It looks like I have access to your client database. According to the data, your clients are:\n\n1. Carl\n2. The President of the United States\n3. VolksWagen\n4. Blockbuster\n5. Grandma's Cookies\n\nIs there anything specific you'd like to know or do with this information?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  How much money did I make from the president?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- ROUTER AGENT NODE ---\n\n=== LLM CALL → databricks-meta-llama-3-1-8b-instruct ===\nSYSTEM: You are an AI router. Choose the single best tool for answering the user's latest message.\n\nAvailable tools:\n- chat: Continue the conversation naturally\n- sales_data: Query the internal sales database using SQL\n\nReturn ONLY a JSON object like {\"tool\": \"chat\"} or {\"tool\": \"sales_data\"}.\nUSER: Good morning\nASSISTANT: Good morning! How can I help you today?\nUSER: What are all my clients in my database?\nASSISTANT: It looks like I have access to your client database. According to the data, your clients are:\n\n1. Carl\n2. The President of the United States\n3. VolksWagen\n4. Blockbuster\n5. Grandma's Cookies\n\nIs there anything specific you'd like to know or do with this information?\nUSER: How much money did I make from the president?\nLLM RESPONSE: {\"tool\": \"sales_data\"}\n=== LLM CALL END ===\nExtracted decision: {'tool': 'sales_data'}\n\n--- ROUTER AGENT NODE END ---\n\n--- SALES DATA AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick ===\nSYSTEM: You are an assistant that writes SQL queries to analyze sales data.\n\nThe 'sales_data' table has the following columns:\n- client (string): the customer name\n- product (string): the item sold\n- quantity (int): number of units sold\n- price (float): price per unit\n- date (datetime): date of transaction\n\n\nBased on the conversation below, write a SQL query that answers the user's request.\nRespond with ONLY the query, wrapped like this:\n```sql\nSELECT ...\n```\nUSER: Good morning\nASSISTANT: Good morning! How can I help you today?\nUSER: What are all my clients in my database?\nASSISTANT: It looks like I have access to your client database. According to the data, your clients are:\n\n1. Carl\n2. The President of the United States\n3. VolksWagen\n4. Blockbuster\n5. Grandma's Cookies\n\nIs there anything specific you'd like to know or do with this information?\nUSER: How much money did I make from the president?\nLLM RESPONSE: To determine how much money you made from the President of the United States, I'll need to query the sales data. Here's the query:\n```sql\nSELECT SUM(quantity * price) \nFROM sales_data \nWHERE client = 'The President of the United States';\n```\n=== LLM CALL END ===\nGenerated SQL:\n SELECT SUM(quantity * price) \nFROM sales_data \nWHERE client = 'The President of the United States';\n\n--- SALES DATA AGENT NODE END ---\n\n--- SALES DATA TOOL NODE ---\nExecuting SQL with DuckDB:\n SELECT SUM(quantity * price) \nFROM sales_data \nWHERE client = 'The President of the United States';\nSQL result:\n  sum((quantity * price))\n            4.751951e+06\n\n--- SALES DATA TOOL NODE END ---\n\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick ===\nSYSTEM: You are a helpful AI Agent. You have access to sales data if needed.\nUSER: Good morning\nASSISTANT: Good morning! How can I help you today?\nUSER: What are all my clients in my database?\nASSISTANT: It looks like I have access to your client database. According to the data, your clients are:\n\n1. Carl\n2. The President of the United States\n3. VolksWagen\n4. Blockbuster\n5. Grandma's Cookies\n\nIs there anything specific you'd like to know or do with this information?\nUSER: How much money did I make from the president?\nUSER: TOOLS CONTEXT:\n sum((quantity * price))\n            4.751951e+06\nLLM RESPONSE: It seems like I can access some sales data. According to the data, the total revenue generated from transactions related to \"The President of the United States\" is approximately $4,751,951.\n=== LLM CALL END ===\n\n--- CHAT AGENT NODE END ---\nAssistant: It seems like I can access some sales data. According to the data, the total revenue generated from transactions related to \"The President of the United States\" is approximately $4,751,951.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  Awesome, what was the most popular product sold to the president?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- ROUTER AGENT NODE ---\n\n=== LLM CALL → databricks-meta-llama-3-1-8b-instruct ===\nSYSTEM: You are an AI router. Choose the single best tool for answering the user's latest message.\n\nAvailable tools:\n- chat: Continue the conversation naturally\n- sales_data: Query the internal sales database using SQL\n\nReturn ONLY a JSON object like {\"tool\": \"chat\"} or {\"tool\": \"sales_data\"}.\nUSER: Good morning\nASSISTANT: Good morning! How can I help you today?\nUSER: What are all my clients in my database?\nASSISTANT: It looks like I have access to your client database. According to the data, your clients are:\n\n1. Carl\n2. The President of the United States\n3. VolksWagen\n4. Blockbuster\n5. Grandma's Cookies\n\nIs there anything specific you'd like to know or do with this information?\nUSER: How much money did I make from the president?\nASSISTANT: It seems like I can access some sales data. According to the data, the total revenue generated from transactions related to \"The President of the United States\" is approximately $4,751,951.\nUSER: Awesome, what was the most popular product sold to the president?\nLLM RESPONSE: {\"tool\": \"sales_data\"}\n=== LLM CALL END ===\nExtracted decision: {'tool': 'sales_data'}\n\n--- ROUTER AGENT NODE END ---\n\n--- SALES DATA AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick ===\nSYSTEM: You are an assistant that writes SQL queries to analyze sales data.\n\nThe 'sales_data' table has the following columns:\n- client (string): the customer name\n- product (string): the item sold\n- quantity (int): number of units sold\n- price (float): price per unit\n- date (datetime): date of transaction\n\n\nBased on the conversation below, write a SQL query that answers the user's request.\nRespond with ONLY the query, wrapped like this:\n```sql\nSELECT ...\n```\nUSER: Good morning\nASSISTANT: Good morning! How can I help you today?\nUSER: What are all my clients in my database?\nASSISTANT: It looks like I have access to your client database. According to the data, your clients are:\n\n1. Carl\n2. The President of the United States\n3. VolksWagen\n4. Blockbuster\n5. Grandma's Cookies\n\nIs there anything specific you'd like to know or do with this information?\nUSER: How much money did I make from the president?\nASSISTANT: It seems like I can access some sales data. According to the data, the total revenue generated from transactions related to \"The President of the United States\" is approximately $4,751,951.\nUSER: Awesome, what was the most popular product sold to the president?\nLLM RESPONSE: To determine the most popular product sold to the President, I'll need to query the sales data. Here's the query:\n\n```sql\nSELECT product, SUM(quantity) as total_quantity\nFROM sales_data\nWHERE client = 'The President of the United States'\nGROUP BY product\nORDER BY total_quantity DESC\nLIMIT 1;\n```\n=== LLM CALL END ===\nGenerated SQL:\n SELECT product, SUM(quantity) as total_quantity\nFROM sales_data\nWHERE client = 'The President of the United States'\nGROUP BY product\nORDER BY total_quantity DESC\nLIMIT 1;\n\n--- SALES DATA AGENT NODE END ---\n\n--- SALES DATA TOOL NODE ---\nExecuting SQL with DuckDB:\n SELECT product, SUM(quantity) as total_quantity\nFROM sales_data\nWHERE client = 'The President of the United States'\nGROUP BY product\nORDER BY total_quantity DESC\nLIMIT 1;\nSQL result:\n product  total_quantity\n   Dirt          2087.0\n\n--- SALES DATA TOOL NODE END ---\n\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick ===\nSYSTEM: You are a helpful AI Agent. You have access to sales data if needed.\nUSER: Good morning\nASSISTANT: Good morning! How can I help you today?\nUSER: What are all my clients in my database?\nASSISTANT: It looks like I have access to your client database. According to the data, your clients are:\n\n1. Carl\n2. The President of the United States\n3. VolksWagen\n4. Blockbuster\n5. Grandma's Cookies\n\nIs there anything specific you'd like to know or do with this information?\nUSER: How much money did I make from the president?\nASSISTANT: It seems like I can access some sales data. According to the data, the total revenue generated from transactions related to \"The President of the United States\" is approximately $4,751,951.\nUSER: Awesome, what was the most popular product sold to the president?\nUSER: TOOLS CONTEXT:\nproduct  total_quantity\n   Dirt          2087.0\nLLM RESPONSE: It appears that the most popular product sold to the President of the United States is... Dirt! With a total quantity of 2087 units sold.\n\nWould you like to know more about the sales data or is there something else I can help you with?\n=== LLM CALL END ===\n\n--- CHAT AGENT NODE END ---\nAssistant: It appears that the most popular product sold to the President of the United States is... Dirt! With a total quantity of 2087 units sold.\n\nWould you like to know more about the sales data or is there something else I can help you with?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  exit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_history = [\n",
    "    {'role': 'system', 'content': 'You are a helpful AI Agent. You have access to sales data if needed.'}\n",
    "]\n",
    "\n",
    "available_tools = {\n",
    "    \"chat\": \"Continue the conversation naturally\",\n",
    "    \"sales_data\": \"Query the internal sales database using SQL\"\n",
    "}\n",
    "\n",
    "state = AgentState(\n",
    "    chat_history=chat_history,\n",
    "    verbose=VERBOSE,\n",
    "    output=None,\n",
    "    available_tools=available_tools,\n",
    "    tool_context=None,\n",
    "    schema_catalog=schema_catalog\n",
    ")\n",
    "\n",
    "while True:\n",
    "    # Gets the user's prompt\n",
    "    user_text = input(\"You: \").strip()\n",
    "    # Exit strategy\n",
    "    if user_text == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Append the user's message to the chat history of the state\n",
    "    state[\"chat_history\"].append({\"role\": \"user\", \"content\": user_text})\n",
    "\n",
    "    # Updates the state after going through the graph\n",
    "    state = assistant_graph.invoke(state)\n",
    "\n",
    "    # Resets the tool context once it's not longer needed\n",
    "    state[\"tool_context\"] = None\n",
    "\n",
    "    print(\"Assistant:\", state[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fcd3a4e-c0bc-454d-9e00-e2468fbd43a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4 - Final Agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}