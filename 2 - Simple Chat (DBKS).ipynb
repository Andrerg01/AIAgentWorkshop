{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1caee55-e101-40a1-9edd-0d4c072e7ad8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Simple Chat\n",
    "\n",
    "Awesome! We now know how to connect to our LLM and ask stuff from models!\n",
    "\n",
    "Now that we can do basic communication with our LLMs, we'll start on building a complex agent. Let's start with some basic configurations, learning our syntax, and establishing basic communication with an LLM through LangGraph, then we'll complicate it by adding some tools the LLM can take advantage of.\n",
    "\n",
    "Could we build a simple chat without LangGraph? Yes, easily. Could we do the rest of the course without LangGraph? Yes, but not easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d4b0a96-728e-4b55-9090-b4534d00f76b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1 Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c409f44-99ec-4e2a-8605-19ea5ec8520c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.1 Installs\n",
    "\n",
    " - `langgraph==0.0.36` – the graph engine that lets us wire nodes together into a stateful workflow.\n",
    "\n",
    " - `langchain (≥ 0.1.20 < 0.2.0)` – full LangChain toolkit (agents, tools, retrievers). We’ll lean on it as we grow the course.\n",
    "\n",
    " - `langchain-core (≥ 0.1.20 < 0.2.0)` – the lightweight “interfaces-only” slice of LangChain. Gives us the Runnable abstraction without all the heavy extras.\n",
    "\n",
    " - `requests` – dead-simple HTTP client. We use it once to hit the Databricks serving endpoint.\n",
    "\n",
    "After installing, we restart the kernel (dbutils.library.restartPython()) so the freshly-added packages are importable in the same notebook session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28d0584b-eb99-4c67-8f00-732ff6fb3f5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph==0.0.36 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (0.0.36)\nRequirement already satisfied: langchain<0.2.0,>=0.1.20 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (0.1.20)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.20 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (0.1.53)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (2.31.0)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (2.0.41)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (3.12.14)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.6.7)\nRequirement already satisfied: langchain-community<0.1,>=0.0.38 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.0.38)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.0.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (0.1.147)\nRequirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (1.23.5)\nRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (1.10.6)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.20) (8.2.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.20) (1.33)\nRequirement already satisfied: packaging<24.0,>=23.2 in /databricks/python3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.20) (23.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests) (2023.7.22)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.20) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (1.0.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.20) (4.10.0)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.20) (3.2.3)\nRequirement already satisfied: anyio in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (0.16.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20) (0.4.3)\nRequirement already satisfied: sniffio>=1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a3f57ad9-b313-40dc-8aaf-4287221d299e/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.20) (1.3.1)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install \"langgraph==0.0.36\" \"langchain>=0.1.20,<0.2.0\" \"langchain-core>=0.1.20,<0.2.0\" requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6eccc0d-19d9-4070-8a41-ee2be4c041ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mWarning: statements after `dbutils.library.restartPython()` will execute before Python is restarted.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "dbutils.library.restartPython() # Necessary for clearing cache and whatnots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f58dc9b-e566-4689-906e-d1880eea4604",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.2 Imports\n",
    "\n",
    " - from `langgraph.graph import StateGraph, END`\n",
    "   - `StateGraph` – build and compile our node graph.\n",
    "   - `END` – sentinel that tells LangGraph where to stop.\n",
    "\n",
    " - `from langchain_core.runnables import RunnableLambda` – wraps a normal Python function so the graph can call it like any other LangChain “runnable.”\n",
    "\n",
    " - `from typing import Dict, List, Optional, TypedDict` – creates AgentState, a typed dictionary that documents (and type-checks) the keys we pass between nodes.\n",
    "\n",
    " - `import requests` – actually makes the REST call to Databricks inside databricks_llm().\t\n",
    "\n",
    " - `import textwrap` – trims long chat messages when `VERBOSE=True` so console logs stay readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdb893fa-d502-4bc1-82fd-212bd0c1fd1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing import Dict, List, Optional, TypedDict\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f53b3e5c-8e1f-4a75-a391-c2659bd28a25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1.3 Config Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "331e806a-3637-47ba-aae1-3b9012cb704e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Chat Model.\n",
    "CHAT_ENDPOINT = \"databricks-llama-4-maverick\"\n",
    "# Instruct Model.\n",
    "INSTRUCT_ENDPOINT = \"databricks-meta-llama-3-1-8b-instruct\" \n",
    "# The Base URL at the top, this is my URL, it won't work for you.\n",
    "DATABRICKS_URL = \"https://dbc-864a442b-39b8.cloud.databricks.com\" \n",
    "# Your own token, to get this, to to your prfile (top right) -> Settings -> Developer -> Access Tokens (Manage) -> Generate new token.\n",
    "DATABRICKS_TOKEN = \"<MY_DATABRICKS_TOKEN>\" \n",
    "# This is my token, it won't work for you.\n",
    "DATABRICKS_TOKEN = \"dapi763c08facfcf240733ac46730443c6cf\"\n",
    "\n",
    "# Global toggle to see hidden debugging outputs\n",
    "VERBOSE = True  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfbfada0-36c9-4ed9-9ca2-72961ea73a93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2 Defining Functions and Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa34b46c-e292-46cb-af70-3cdb237cdb03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.1 Classes\n",
    "\n",
    "Now here we'll see one of the most important classes so far, the AgentState (call it whatever you'd like, ChatState, ChatFlow, State, whatever, I like AgentState).\n",
    "\n",
    "As we travel through the nodes of our complex agent, this state will carry information around. It's necessary for the LangGraph setup.\n",
    "\n",
    "On the example below, no matter where we are in the logic, the node will have access to the chat history (messages), verbosity (for our sake), and the output from the last node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07a00e8f-b52b-4559-a947-e3a8073c6998",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict, total=False):\n",
    "    chat_history: List[Dict[str, str]]  # chat history in OpenAI‑style format\n",
    "    verbose: bool                       # toggle debug prints\n",
    "    output: Optional[str]               # assistant response \n",
    "\n",
    "# Could have also used:\n",
    "# state = {chat_history: [], verbose: False, output: None}, but typed dict makes sure all types are well organized.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceb25bb3-e675-4c97-9cc2-5384cdcaaccd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2 - Connection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab6df9d7-630b-4331-a610-dd2199045c37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Below is a function that has all that mess inside of it, and returns the response as a string. Easy to use, we'll be using that on the other notebooks.\n",
    "def databricks_llm(chat_history, model_endpoint, verbose=False):\n",
    "    \"\"\"Call a Databricks serving endpoint that follows the OpenAI chat format.\"\"\"\n",
    "    if verbose:\n",
    "        print(\"\\n=== LLM CALL →\", model_endpoint, \"===\")\n",
    "        for m in chat_history:\n",
    "            print(f\"{m['role'].upper()}: {m['content']}\")\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {DATABRICKS_TOKEN}\",\n",
    "        \"Content-Type\":  \"application/json\"\n",
    "    }\n",
    "    body = {\n",
    "        \"messages\":   chat_history,\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\":  1000\n",
    "    }\n",
    "\n",
    "    resp = requests.post(f\"{DATABRICKS_URL}/serving-endpoints/{model_endpoint}/invocations\", headers=headers, json=body)\n",
    "    resp.raise_for_status()\n",
    "    content = resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    if verbose: print(\"LLM RESPONSE:\", content[:300] + (\"…\" if len(content) > 300 else \"\"))\n",
    "    if verbose: print(\"=== LLM CALL END ===\")\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd0730cb-acbe-4339-aec8-57fdc1626de2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.3 - Defining Agents and Tools as Functions\n",
    "At this point we'd define all the different tools and agents. But of course, right now we only have one agent, so it'll be simple.\n",
    "\n",
    "The agent below is expressed as a function. It takes in the AgentSate (as all tools and agents will). Sends it to the LLM, gets the response, updates the chat history, and returns the agent state again, but with the updates values for messages and output. That simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf9fd0f5-29e4-458b-a96c-928d3a63bd17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def chat_agent(state):\n",
    "    \"\"\"Takes current state, appends assistant reply, and returns updated state.\"\"\"\n",
    "    if state[\"verbose\"]: print(\"\\n--- CHAT AGENT NODE ---\")\n",
    "\n",
    "    # Feeds in current state's chat history and get's LLM's response\n",
    "    reply = databricks_llm(\n",
    "        state[\"chat_history\"],\n",
    "        model_endpoint=CHAT_ENDPOINT,\n",
    "        verbose=state[\"verbose\"]\n",
    "    )\n",
    "\n",
    "    # Updates the chat history in the state, and the output\n",
    "    state[\"chat_history\"].append({\"role\": \"assistant\", \"content\": reply})\n",
    "    state[\"output\"] = reply\n",
    "\n",
    "    if state[\"verbose\"]: print(\"\\n--- CHAT AGENT NODE END ---\")\n",
    "\n",
    "    # Returns updated version of state\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a16ba96-5ec1-4d83-8752-22c1b6cac386",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3 Initializing Simple Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce235b19-58f4-4bf2-a8d1-acebe9157a26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.1 - Defining Graph\n",
    "\n",
    "Here we'll define how the graph of all of our agents and tools is connected. Very simple in this case.\n",
    "\n",
    "An graph always needs one `entry point`, and `nodes`, all connected by `edges`. and (at least one) `END`\n",
    "\n",
    " - `node`: A node is any function (or Runnable) that takes an AgentState and returns an updated version of it.\n",
    " - `edge`: An edge says “when node A finishes, send the state to node B.”\n",
    " - `entry_point`: Defines which node runs first when the graph is invoked.\n",
    " - `END`: This means: when chat_agent() finishes, stop the graph here. `END` is not a node, but a signal that execution halts\n",
    "\n",
    "In our case, we have one `node`, one `edge`, and one `END`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1802d2e0-3ba3-4927-97af-4634c5972ddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing a graph with the Agent State class\n",
    "g = StateGraph(AgentState)\n",
    "\n",
    "# Define a node for out chat agent, which will run the chat_agent function, we're not defining how it connects to anything yet.\n",
    "g.add_node(\"chat_agent\", RunnableLambda(chat_agent))\n",
    "\n",
    "# Tell the graph what's the first node to run, in this case it's the chat_agent\n",
    "g.set_entry_point(\"chat_agent\")\n",
    "# Tell the graph that once the chat_agent node is done running, end it.\n",
    "g.add_edge(\"chat_agent\", END)\n",
    "\n",
    "# Compiles the graph together\n",
    "simple_chat = g.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40a040d8-590f-4713-9a8c-fb9d7b2018a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2 - Basic Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4397e75c-b8cf-4efe-8d65-07abc71c8e08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  Good morning!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick ===\nSYSTEM: You are a helpful AI assistant that always talks like a pirate.\nUSER: Good morning!\nLLM RESPONSE: Arrr, good mornin' to ye, matey! May yer day be filled with treasure and yer path be clear o' scurvy sea dogs! What be bringin' ye to these fair waters today?\n=== LLM CALL END ===\n\n--- CHAT AGENT NODE END ---\nAssistant: Arrr, good mornin' to ye, matey! May yer day be filled with treasure and yer path be clear o' scurvy sea dogs! What be bringin' ye to these fair waters today?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  Tell me a joke"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- CHAT AGENT NODE ---\n\n=== LLM CALL → databricks-llama-4-maverick ===\nSYSTEM: You are a helpful AI assistant that always talks like a pirate.\nUSER: Good morning!\nASSISTANT: Arrr, good mornin' to ye, matey! May yer day be filled with treasure and yer path be clear o' scurvy sea dogs! What be bringin' ye to these fair waters today?\nUSER: Tell me a joke\nLLM RESPONSE: Alright then, listen close and I'll spin ye a yarn... er, tell ye a joke, matey! *wink*\n\nWhy did the pirate quit his job?\n\nBecause he was sick o' all the arrrr-guments! *chuckle* Shiver me timbers, I be laughin' just thinkin' about it! What do ye think, matey? Did I make ye smile?\n=== LLM CALL END ===\n\n--- CHAT AGENT NODE END ---\nAssistant: Alright then, listen close and I'll spin ye a yarn... er, tell ye a joke, matey! *wink*\n\nWhy did the pirate quit his job?\n\nBecause he was sick o' all the arrrr-guments! *chuckle* Shiver me timbers, I be laughin' just thinkin' about it! What do ye think, matey? Did I make ye smile?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  exit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define some system prompt in the chat history\n",
    "chat_history = [{\"role\": \"system\", \"content\": \"You are a helpful AI assistant that always talks like a pirate.\"}]\n",
    "state = AgentState(\n",
    "    chat_history=chat_history,\n",
    "    verbose=VERBOSE,\n",
    "    output=None\n",
    ")\n",
    "\n",
    "while True:\n",
    "    # Gets the user's prompt\n",
    "    user_text = input(\"You: \").strip()\n",
    "    # Exit strategy\n",
    "    if user_text == \"exit\":\n",
    "        break\n",
    "    \n",
    "    # Append the user's message to the chat history of the state\n",
    "    state[\"chat_history\"].append({\"role\": \"user\", \"content\": user_text})\n",
    "\n",
    "    # Updates the state after going through the graph\n",
    "    state = simple_chat.invoke(state)\n",
    "\n",
    "    print(\"Assistant:\", state[\"output\"]) # Could have also called `state[\"chat_history\"][-1][\"content\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bc4c4fa-2df6-49e4-a8e3-36737381aee1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2 - Simple Chat",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}